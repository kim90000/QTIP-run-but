{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "32e9c983562e4a02959e25509c3b7958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1afbae3f809f4fdfbb2b73ac751ef3e4",
              "IPY_MODEL_e93268012d2341bd966f95fb889eda61",
              "IPY_MODEL_3249ebaf3ea74d17b0750f594531a00e"
            ],
            "layout": "IPY_MODEL_205179e3b1b345eb95becda7cac9745f"
          }
        },
        "1afbae3f809f4fdfbb2b73ac751ef3e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0e6887ba9d4478f845997378000d3eb",
            "placeholder": "​",
            "style": "IPY_MODEL_dc2b4f73a3594549b3992cc3fb936bd3",
            "value": "config.json: 100%"
          }
        },
        "e93268012d2341bd966f95fb889eda61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee0c5306533645349a3b8eb80242fdd9",
            "max": 1117,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b661a0975e154ca2b01c9299630faa2d",
            "value": 1117
          }
        },
        "3249ebaf3ea74d17b0750f594531a00e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cd2b548d1d642ea89c4a6ecdf147e86",
            "placeholder": "​",
            "style": "IPY_MODEL_a8db7a4943cd41b5aa46cd437b04bd39",
            "value": " 1.12k/1.12k [00:00&lt;00:00, 142kB/s]"
          }
        },
        "205179e3b1b345eb95becda7cac9745f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0e6887ba9d4478f845997378000d3eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc2b4f73a3594549b3992cc3fb936bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee0c5306533645349a3b8eb80242fdd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b661a0975e154ca2b01c9299630faa2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cd2b548d1d642ea89c4a6ecdf147e86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8db7a4943cd41b5aa46cd437b04bd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7a66fdcdca549cfa9d62108f20ec040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f7c59177ba84e48a3b28dba0332daa0",
              "IPY_MODEL_b90fe51038304a5aaed65d9062c3c869",
              "IPY_MODEL_7ac3ef8c427c4f2ca13fa6a826d57c7e"
            ],
            "layout": "IPY_MODEL_e764575a7b6d401f80d5a887dd9c7892"
          }
        },
        "7f7c59177ba84e48a3b28dba0332daa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ac945c81f884f069ab48f0d9f0b1ae4",
            "placeholder": "​",
            "style": "IPY_MODEL_109e1f1bf4844012ad02119d3d5d507a",
            "value": "model.safetensors: 100%"
          }
        },
        "b90fe51038304a5aaed65d9062c3c869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf8cf0edcc4c4f39a1b16b2863099a53",
            "max": 3852517272,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b5f8b3ee2bc492fae18d9a719eb1884",
            "value": 3852517272
          }
        },
        "7ac3ef8c427c4f2ca13fa6a826d57c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0f06c084dd74070a359f67982ef5a4a",
            "placeholder": "​",
            "style": "IPY_MODEL_414f959f30784bc9896d450e5814d8f2",
            "value": " 3.85G/3.85G [00:20&lt;00:00, 230MB/s]"
          }
        },
        "e764575a7b6d401f80d5a887dd9c7892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac945c81f884f069ab48f0d9f0b1ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "109e1f1bf4844012ad02119d3d5d507a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf8cf0edcc4c4f39a1b16b2863099a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b5f8b3ee2bc492fae18d9a719eb1884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0f06c084dd74070a359f67982ef5a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "414f959f30784bc9896d450e5814d8f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e58e100f2f243cdb0a5b0f68a2beb02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9510164bbf546998c581ee01cec2206",
              "IPY_MODEL_4d5831f4e7cb47e89d7ef0b56e61353c",
              "IPY_MODEL_088837e9cbc94f1d8c138369b87360b3"
            ],
            "layout": "IPY_MODEL_8cf3aed0051f4be5ade99c144f7b0219"
          }
        },
        "e9510164bbf546998c581ee01cec2206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_436198c9f3704e4da0d2cf4a8c639c86",
            "placeholder": "​",
            "style": "IPY_MODEL_bab2c672a45d4390962927bcb5a0bc28",
            "value": "generation_config.json: 100%"
          }
        },
        "4d5831f4e7cb47e89d7ef0b56e61353c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52d5ce8e57db402d9950f44fafef8652",
            "max": 217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_684bc69015b4442f901c3e359877c659",
            "value": 217
          }
        },
        "088837e9cbc94f1d8c138369b87360b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_313507690ef942cd9def9197ef25943c",
            "placeholder": "​",
            "style": "IPY_MODEL_2643d401f1ff4ae9b026d10b7b019fda",
            "value": " 217/217 [00:00&lt;00:00, 31.0kB/s]"
          }
        },
        "8cf3aed0051f4be5ade99c144f7b0219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "436198c9f3704e4da0d2cf4a8c639c86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab2c672a45d4390962927bcb5a0bc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52d5ce8e57db402d9950f44fafef8652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684bc69015b4442f901c3e359877c659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "313507690ef942cd9def9197ef25943c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2643d401f1ff4ae9b026d10b7b019fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "370128acb0874618aa653dfc4bafd4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc1dc64ea190451e83243b01eaee938c",
              "IPY_MODEL_34885bd04dcd46e2b1ecbf34e0e7a8df",
              "IPY_MODEL_a08149c6e2384c1b90c87802d0b71568"
            ],
            "layout": "IPY_MODEL_94e7c4f9e1324a669b89831c575521e5"
          }
        },
        "bc1dc64ea190451e83243b01eaee938c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6006dbfbfc2492dad4a8e62aa4b33c0",
            "placeholder": "​",
            "style": "IPY_MODEL_a875185ffc044fc88402cd9e8edf70b5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "34885bd04dcd46e2b1ecbf34e0e7a8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce6f1ce005684680bf13b05f1cfc8405",
            "max": 50500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f7b59cbed8d478ca0dfbef6449fe76b",
            "value": 50500
          }
        },
        "a08149c6e2384c1b90c87802d0b71568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5bce554bd78462c941407a54ce0e178",
            "placeholder": "​",
            "style": "IPY_MODEL_133ac8471bc74a439a85b7528a89fcc1",
            "value": " 50.5k/50.5k [00:00&lt;00:00, 1.73MB/s]"
          }
        },
        "94e7c4f9e1324a669b89831c575521e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6006dbfbfc2492dad4a8e62aa4b33c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a875185ffc044fc88402cd9e8edf70b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce6f1ce005684680bf13b05f1cfc8405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7b59cbed8d478ca0dfbef6449fe76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5bce554bd78462c941407a54ce0e178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "133ac8471bc74a439a85b7528a89fcc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10debea8f0f94f88b546d4c6d0fb045a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b978f29f802e4c60a4348d516d712e3b",
              "IPY_MODEL_7d2d641a0abd46a98a248529858dbbed",
              "IPY_MODEL_32ebb3942702416582ec29cd163672eb"
            ],
            "layout": "IPY_MODEL_9251b234b57a4167a5172e8cd12d37b1"
          }
        },
        "b978f29f802e4c60a4348d516d712e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c80cac65ee104423b42c3ba2e86c4251",
            "placeholder": "​",
            "style": "IPY_MODEL_8f853cc2a972435b8a1983558d21c3b4",
            "value": "tokenizer.json: 100%"
          }
        },
        "7d2d641a0abd46a98a248529858dbbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86e2659b02a742e4af823a4c1017f190",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05df02d5b5b7401981a0d04ed2a16443",
            "value": 9085657
          }
        },
        "32ebb3942702416582ec29cd163672eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_011126fe4baf4d3b885939c780d3196a",
            "placeholder": "​",
            "style": "IPY_MODEL_f208e2cff1e1451e9f70f522dadad3e8",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 39.6MB/s]"
          }
        },
        "9251b234b57a4167a5172e8cd12d37b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c80cac65ee104423b42c3ba2e86c4251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f853cc2a972435b8a1983558d21c3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86e2659b02a742e4af823a4c1017f190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05df02d5b5b7401981a0d04ed2a16443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "011126fe4baf4d3b885939c780d3196a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f208e2cff1e1451e9f70f522dadad3e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_id = \"relaxml/Llama-3.1-8B-Instruct-QTIP-2Bit\"\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405,
          "referenced_widgets": [
            "32e9c983562e4a02959e25509c3b7958",
            "1afbae3f809f4fdfbb2b73ac751ef3e4",
            "e93268012d2341bd966f95fb889eda61",
            "3249ebaf3ea74d17b0750f594531a00e",
            "205179e3b1b345eb95becda7cac9745f",
            "d0e6887ba9d4478f845997378000d3eb",
            "dc2b4f73a3594549b3992cc3fb936bd3",
            "ee0c5306533645349a3b8eb80242fdd9",
            "b661a0975e154ca2b01c9299630faa2d",
            "9cd2b548d1d642ea89c4a6ecdf147e86",
            "a8db7a4943cd41b5aa46cd437b04bd39",
            "a7a66fdcdca549cfa9d62108f20ec040",
            "7f7c59177ba84e48a3b28dba0332daa0",
            "b90fe51038304a5aaed65d9062c3c869",
            "7ac3ef8c427c4f2ca13fa6a826d57c7e",
            "e764575a7b6d401f80d5a887dd9c7892",
            "9ac945c81f884f069ab48f0d9f0b1ae4",
            "109e1f1bf4844012ad02119d3d5d507a",
            "bf8cf0edcc4c4f39a1b16b2863099a53",
            "1b5f8b3ee2bc492fae18d9a719eb1884",
            "e0f06c084dd74070a359f67982ef5a4a",
            "414f959f30784bc9896d450e5814d8f2",
            "3e58e100f2f243cdb0a5b0f68a2beb02",
            "e9510164bbf546998c581ee01cec2206",
            "4d5831f4e7cb47e89d7ef0b56e61353c",
            "088837e9cbc94f1d8c138369b87360b3",
            "8cf3aed0051f4be5ade99c144f7b0219",
            "436198c9f3704e4da0d2cf4a8c639c86",
            "bab2c672a45d4390962927bcb5a0bc28",
            "52d5ce8e57db402d9950f44fafef8652",
            "684bc69015b4442f901c3e359877c659",
            "313507690ef942cd9def9197ef25943c",
            "2643d401f1ff4ae9b026d10b7b019fda",
            "370128acb0874618aa653dfc4bafd4df",
            "bc1dc64ea190451e83243b01eaee938c",
            "34885bd04dcd46e2b1ecbf34e0e7a8df",
            "a08149c6e2384c1b90c87802d0b71568",
            "94e7c4f9e1324a669b89831c575521e5",
            "a6006dbfbfc2492dad4a8e62aa4b33c0",
            "a875185ffc044fc88402cd9e8edf70b5",
            "ce6f1ce005684680bf13b05f1cfc8405",
            "4f7b59cbed8d478ca0dfbef6449fe76b",
            "f5bce554bd78462c941407a54ce0e178",
            "133ac8471bc74a439a85b7528a89fcc1",
            "10debea8f0f94f88b546d4c6d0fb045a",
            "b978f29f802e4c60a4348d516d712e3b",
            "7d2d641a0abd46a98a248529858dbbed",
            "32ebb3942702416582ec29cd163672eb",
            "9251b234b57a4167a5172e8cd12d37b1",
            "c80cac65ee104423b42c3ba2e86c4251",
            "8f853cc2a972435b8a1983558d21c3b4",
            "86e2659b02a742e4af823a4c1017f190",
            "05df02d5b5b7401981a0d04ed2a16443",
            "011126fe4baf4d3b885939c780d3196a",
            "f208e2cff1e1451e9f70f522dadad3e8"
          ]
        },
        "id": "wncfni-z0LRP",
        "outputId": "135e390b-140e-4041-826f-76c117542b80"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32e9c983562e4a02959e25509c3b7958"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7a66fdcdca549cfa9d62108f20ec040"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at relaxml/Llama-3.1-8B-Instruct-QTIP-2Bit were not used when initializing LlamaForCausalLM: {'model.layers.13.self_attn.v_proj.trellis', 'model.layers.21.self_attn.v_proj.tlut', 'model.layers.24.self_attn.o_proj.SV', 'model.layers.13.self_attn.k_proj.SU', 'model.layers.22.mlp.gate_proj.SV', 'model.layers.0.self_attn.q_proj.SU', 'model.layers.31.self_attn.q_proj.tlut', 'model.layers.24.mlp.down_proj.tlut', 'model.layers.13.mlp.up_proj.SU', 'model.layers.23.mlp.gate_proj.trellis', 'model.layers.22.self_attn.o_proj.tlut', 'model.layers.3.mlp.up_proj.SV', 'model.layers.4.self_attn.v_proj.SU', 'model.layers.7.mlp.gate_proj.tlut', 'model.layers.22.mlp.up_proj.SV', 'model.layers.0.self_attn.v_proj.SV', 'model.layers.13.self_attn.q_proj.tlut', 'model.layers.10.self_attn.k_proj.trellis', 'model.layers.3.self_attn.k_proj.tlut', 'model.layers.21.self_attn.q_proj.trellis', 'model.layers.19.self_attn.k_proj.tlut', 'model.layers.22.self_attn.k_proj.SV', 'model.layers.16.mlp.up_proj.tlut', 'model.layers.13.self_attn.v_proj.SV', 'model.layers.23.self_attn.q_proj.tlut', 'model.layers.30.self_attn.k_proj.trellis', 'model.layers.16.self_attn.q_proj.trellis', 'model.layers.25.mlp.gate_proj.trellis', 'model.layers.13.mlp.up_proj.trellis', 'model.layers.18.mlp.down_proj.SU', 'model.layers.26.self_attn.q_proj.tlut', 'model.layers.9.self_attn.k_proj.SV', 'model.layers.7.self_attn.o_proj.SV', 'model.layers.15.mlp.gate_proj.trellis', 'model.layers.23.mlp.up_proj.tlut', 'model.layers.11.self_attn.q_proj.SV', 'model.layers.9.mlp.gate_proj.trellis', 'model.layers.5.mlp.down_proj.SU', 'model.layers.21.self_attn.k_proj.trellis', 'model.layers.11.mlp.up_proj.trellis', 'model.layers.22.mlp.up_proj.SU', 'model.layers.21.mlp.gate_proj.trellis', 'model.layers.16.self_attn.q_proj.tlut', 'model.layers.24.mlp.gate_proj.SV', 'model.layers.24.self_attn.o_proj.tlut', 'model.layers.14.self_attn.k_proj.tlut', 'model.layers.8.mlp.down_proj.SU', 'model.layers.10.mlp.gate_proj.tlut', 'model.layers.8.mlp.gate_proj.tlut', 'model.layers.1.self_attn.k_proj.SV', 'model.layers.30.self_attn.v_proj.trellis', 'model.layers.4.self_attn.k_proj.SV', 'model.layers.29.mlp.gate_proj.trellis', 'model.layers.23.mlp.gate_proj.SU', 'model.layers.31.self_attn.k_proj.tlut', 'model.layers.18.mlp.up_proj.trellis', 'model.layers.11.self_attn.k_proj.SU', 'model.layers.6.self_attn.o_proj.SV', 'model.layers.30.self_attn.q_proj.SV', 'model.layers.31.mlp.down_proj.trellis', 'model.layers.7.mlp.gate_proj.SV', 'model.layers.10.mlp.down_proj.SU', 'model.layers.10.self_attn.k_proj.SV', 'model.layers.12.self_attn.v_proj.SU', 'model.layers.13.mlp.gate_proj.trellis', 'model.layers.18.self_attn.q_proj.SV', 'model.layers.21.self_attn.o_proj.SV', 'model.layers.27.self_attn.v_proj.tlut', 'model.layers.29.self_attn.o_proj.trellis', 'model.layers.9.self_attn.q_proj.SU', 'model.layers.1.self_attn.q_proj.tlut', 'model.layers.23.self_attn.v_proj.SU', 'model.layers.4.self_attn.v_proj.SV', 'model.layers.30.self_attn.v_proj.SU', 'model.layers.20.mlp.gate_proj.SV', 'model.layers.3.mlp.gate_proj.tlut', 'model.layers.24.self_attn.q_proj.trellis', 'model.layers.2.self_attn.k_proj.SV', 'model.layers.2.self_attn.q_proj.trellis', 'model.layers.11.self_attn.v_proj.SU', 'model.layers.30.mlp.down_proj.trellis', 'model.layers.7.mlp.up_proj.trellis', 'model.layers.1.self_attn.q_proj.trellis', 'model.layers.2.mlp.gate_proj.trellis', 'model.layers.9.self_attn.q_proj.trellis', 'model.layers.0.mlp.gate_proj.SU', 'model.layers.4.mlp.up_proj.SV', 'model.layers.23.mlp.down_proj.SU', 'model.layers.7.mlp.gate_proj.SU', 'model.layers.25.self_attn.o_proj.SV', 'model.layers.28.self_attn.q_proj.SU', 'model.layers.29.mlp.down_proj.SU', 'model.layers.16.self_attn.k_proj.SU', 'model.layers.26.mlp.up_proj.SV', 'model.layers.18.self_attn.q_proj.trellis', 'model.layers.10.self_attn.o_proj.trellis', 'model.layers.23.mlp.up_proj.trellis', 'model.layers.15.mlp.down_proj.SV', 'model.layers.19.self_attn.o_proj.tlut', 'model.layers.27.mlp.gate_proj.trellis', 'model.layers.10.mlp.down_proj.trellis', 'model.layers.4.mlp.gate_proj.SU', 'model.layers.19.mlp.up_proj.SU', 'model.layers.13.mlp.gate_proj.SU', 'model.layers.27.self_attn.o_proj.trellis', 'model.layers.6.self_attn.v_proj.SV', 'model.layers.0.self_attn.v_proj.trellis', 'model.layers.18.self_attn.v_proj.tlut', 'model.layers.22.self_attn.k_proj.tlut', 'model.layers.15.self_attn.k_proj.tlut', 'model.layers.9.mlp.gate_proj.tlut', 'model.layers.15.self_attn.o_proj.trellis', 'model.layers.1.mlp.gate_proj.trellis', 'model.layers.11.mlp.gate_proj.SU', 'model.layers.5.mlp.up_proj.tlut', 'model.layers.6.self_attn.q_proj.tlut', 'model.layers.13.mlp.up_proj.tlut', 'model.layers.4.mlp.gate_proj.trellis', 'model.layers.27.self_attn.q_proj.trellis', 'model.layers.18.mlp.gate_proj.SV', 'model.layers.28.mlp.down_proj.trellis', 'model.layers.26.mlp.gate_proj.SU', 'model.layers.31.mlp.gate_proj.SV', 'model.layers.21.self_attn.o_proj.tlut', 'model.layers.28.mlp.down_proj.SU', 'model.layers.19.mlp.gate_proj.trellis', 'model.layers.4.self_attn.o_proj.trellis', 'model.layers.4.self_attn.v_proj.trellis', 'model.layers.0.self_attn.k_proj.SV', 'model.layers.2.self_attn.q_proj.SV', 'model.layers.5.self_attn.o_proj.trellis', 'model.layers.28.self_attn.v_proj.SV', 'model.layers.28.self_attn.q_proj.tlut', 'model.layers.30.self_attn.q_proj.SU', 'model.layers.3.self_attn.v_proj.SU', 'model.layers.25.self_attn.k_proj.SV', 'model.layers.30.mlp.up_proj.SV', 'model.layers.20.self_attn.q_proj.trellis', 'model.layers.18.self_attn.q_proj.SU', 'model.layers.1.self_attn.o_proj.trellis', 'model.layers.27.mlp.up_proj.SU', 'model.layers.15.mlp.up_proj.SV', 'model.layers.24.self_attn.q_proj.tlut', 'model.layers.17.mlp.up_proj.SU', 'model.layers.1.mlp.down_proj.SU', 'model.layers.24.self_attn.v_proj.SU', 'model.layers.13.mlp.up_proj.SV', 'model.layers.7.self_attn.v_proj.SU', 'model.layers.10.self_attn.q_proj.SU', 'model.layers.10.mlp.gate_proj.SU', 'model.layers.21.mlp.gate_proj.SV', 'model.layers.14.mlp.gate_proj.SU', 'model.layers.6.mlp.down_proj.SV', 'model.layers.10.self_attn.o_proj.SU', 'model.layers.21.self_attn.q_proj.SV', 'model.layers.3.self_attn.k_proj.SU', 'model.layers.20.self_attn.v_proj.SU', 'model.layers.26.mlp.gate_proj.trellis', 'model.layers.14.self_attn.v_proj.SU', 'model.layers.28.self_attn.k_proj.trellis', 'model.layers.6.mlp.gate_proj.tlut', 'model.layers.25.mlp.up_proj.SU', 'model.layers.15.self_attn.v_proj.trellis', 'model.layers.25.mlp.down_proj.SU', 'model.layers.2.self_attn.v_proj.trellis', 'model.layers.2.self_attn.q_proj.SU', 'model.layers.11.self_attn.o_proj.tlut', 'model.layers.23.self_attn.v_proj.tlut', 'model.layers.4.mlp.up_proj.tlut', 'model.layers.5.mlp.gate_proj.tlut', 'model.layers.20.mlp.up_proj.SV', 'model.layers.28.self_attn.k_proj.SV', 'model.layers.7.self_attn.v_proj.SV', 'model.layers.29.self_attn.o_proj.tlut', 'model.layers.16.self_attn.k_proj.trellis', 'model.layers.11.self_attn.o_proj.SU', 'model.layers.5.self_attn.q_proj.SV', 'model.layers.18.mlp.down_proj.SV', 'model.layers.27.mlp.gate_proj.tlut', 'model.layers.30.mlp.up_proj.tlut', 'model.layers.15.self_attn.q_proj.SU', 'model.layers.17.self_attn.v_proj.SU', 'model.layers.9.self_attn.o_proj.SU', 'model.layers.5.mlp.down_proj.tlut', 'model.layers.1.self_attn.o_proj.SU', 'model.layers.20.self_attn.o_proj.SU', 'model.layers.21.self_attn.q_proj.SU', 'model.layers.27.mlp.up_proj.tlut', 'model.layers.30.mlp.down_proj.SV', 'model.layers.25.self_attn.v_proj.SV', 'model.layers.22.self_attn.k_proj.SU', 'model.layers.21.mlp.down_proj.trellis', 'model.layers.26.mlp.down_proj.SU', 'model.layers.8.self_attn.o_proj.trellis', 'model.layers.8.self_attn.v_proj.tlut', 'model.layers.22.self_attn.v_proj.tlut', 'model.layers.25.self_attn.q_proj.SV', 'model.layers.3.mlp.down_proj.SV', 'model.layers.12.self_attn.k_proj.SV', 'model.layers.30.self_attn.k_proj.tlut', 'model.layers.29.mlp.down_proj.SV', 'model.layers.7.mlp.up_proj.SU', 'model.layers.3.self_attn.v_proj.trellis', 'model.layers.8.mlp.up_proj.SU', 'model.layers.14.self_attn.q_proj.SV', 'model.layers.16.mlp.gate_proj.tlut', 'model.layers.26.mlp.up_proj.SU', 'model.layers.29.mlp.up_proj.SV', 'model.layers.7.mlp.up_proj.tlut', 'model.layers.4.self_attn.q_proj.SU', 'model.layers.19.self_attn.v_proj.trellis', 'model.layers.22.mlp.down_proj.SU', 'model.layers.13.mlp.down_proj.SV', 'model.layers.18.self_attn.k_proj.trellis', 'model.layers.18.mlp.up_proj.tlut', 'model.layers.22.mlp.down_proj.trellis', 'model.layers.9.self_attn.v_proj.SU', 'model.layers.26.mlp.gate_proj.tlut', 'model.layers.19.self_attn.k_proj.trellis', 'model.layers.20.mlp.down_proj.trellis', 'model.layers.20.self_attn.q_proj.SV', 'model.layers.27.self_attn.k_proj.tlut', 'model.layers.12.mlp.gate_proj.SU', 'model.layers.16.mlp.down_proj.trellis', 'model.layers.5.mlp.gate_proj.SU', 'model.layers.8.self_attn.o_proj.tlut', 'model.layers.17.mlp.down_proj.SV', 'model.layers.21.mlp.gate_proj.SU', 'model.layers.15.self_attn.q_proj.SV', 'model.layers.10.self_attn.v_proj.trellis', 'model.layers.0.self_attn.o_proj.SV', 'model.layers.16.mlp.up_proj.trellis', 'model.layers.24.mlp.down_proj.SU', 'model.layers.8.self_attn.v_proj.trellis', 'model.layers.13.mlp.down_proj.trellis', 'model.layers.5.mlp.up_proj.SU', 'model.layers.16.self_attn.v_proj.SU', 'model.layers.11.mlp.gate_proj.tlut', 'model.layers.17.self_attn.v_proj.SV', 'model.layers.29.self_attn.k_proj.trellis', 'model.layers.5.self_attn.v_proj.tlut', 'model.layers.16.mlp.down_proj.SV', 'model.layers.2.mlp.gate_proj.tlut', 'model.layers.5.self_attn.k_proj.tlut', 'model.layers.2.mlp.gate_proj.SV', 'model.layers.7.self_attn.q_proj.SU', 'model.layers.15.mlp.gate_proj.SU', 'model.layers.28.mlp.gate_proj.SV', 'model.layers.8.self_attn.k_proj.SV', 'model.layers.25.mlp.gate_proj.tlut', 'model.layers.7.mlp.down_proj.tlut', 'model.layers.13.mlp.gate_proj.SV', 'model.layers.22.self_attn.k_proj.trellis', 'model.layers.26.self_attn.o_proj.SU', 'model.layers.29.mlp.down_proj.tlut', 'model.layers.11.self_attn.k_proj.SV', 'model.layers.17.self_attn.k_proj.tlut', 'model.layers.14.self_attn.q_proj.tlut', 'model.layers.3.mlp.down_proj.SU', 'model.layers.4.mlp.down_proj.trellis', 'model.layers.5.mlp.up_proj.SV', 'model.layers.20.self_attn.v_proj.SV', 'model.layers.30.self_attn.q_proj.trellis', 'model.layers.14.mlp.gate_proj.trellis', 'model.layers.28.self_attn.q_proj.trellis', 'model.layers.16.self_attn.o_proj.tlut', 'model.layers.4.mlp.down_proj.SU', 'model.layers.3.self_attn.q_proj.tlut', 'model.layers.19.self_attn.k_proj.SV', 'model.layers.5.mlp.gate_proj.SV', 'model.layers.24.self_attn.o_proj.SU', 'model.layers.8.self_attn.q_proj.trellis', 'model.layers.7.self_attn.v_proj.tlut', 'model.layers.8.self_attn.v_proj.SU', 'model.layers.16.self_attn.v_proj.SV', 'model.layers.16.mlp.gate_proj.SV', 'model.layers.28.mlp.down_proj.SV', 'model.layers.29.mlp.down_proj.trellis', 'model.layers.31.mlp.gate_proj.trellis', 'model.layers.28.self_attn.k_proj.tlut', 'model.layers.14.mlp.up_proj.SU', 'model.layers.0.self_attn.o_proj.trellis', 'model.layers.26.self_attn.k_proj.SV', 'model.layers.26.self_attn.o_proj.SV', 'model.layers.20.mlp.gate_proj.SU', 'model.layers.17.self_attn.v_proj.trellis', 'model.layers.31.self_attn.v_proj.SV', 'model.layers.27.self_attn.k_proj.SV', 'model.layers.16.self_attn.o_proj.SV', 'model.layers.29.mlp.up_proj.SU', 'model.layers.17.self_attn.o_proj.tlut', 'model.layers.9.self_attn.v_proj.tlut', 'model.layers.19.mlp.down_proj.tlut', 'model.layers.4.self_attn.o_proj.tlut', 'model.layers.29.self_attn.v_proj.SU', 'model.layers.31.self_attn.k_proj.SU', 'model.layers.31.self_attn.q_proj.trellis', 'model.layers.7.mlp.down_proj.SV', 'model.layers.18.self_attn.k_proj.tlut', 'model.layers.25.mlp.down_proj.trellis', 'model.layers.23.self_attn.q_proj.SU', 'model.layers.9.self_attn.k_proj.tlut', 'model.layers.30.mlp.gate_proj.trellis', 'model.layers.0.self_attn.k_proj.tlut', 'model.layers.13.mlp.gate_proj.tlut', 'model.layers.2.self_attn.o_proj.SV', 'model.layers.1.self_attn.k_proj.SU', 'model.layers.7.self_attn.o_proj.tlut', 'model.layers.1.self_attn.v_proj.SV', 'model.layers.21.self_attn.o_proj.trellis', 'model.layers.6.mlp.up_proj.trellis', 'model.layers.9.mlp.gate_proj.SU', 'model.layers.12.self_attn.o_proj.SU', 'model.layers.18.mlp.gate_proj.tlut', 'model.layers.13.self_attn.k_proj.trellis', 'model.layers.3.mlp.down_proj.trellis', 'model.layers.0.mlp.down_proj.tlut', 'model.layers.4.mlp.gate_proj.tlut', 'model.layers.6.mlp.up_proj.SU', 'model.layers.31.self_attn.q_proj.SV', 'model.layers.7.self_attn.k_proj.SV', 'model.layers.12.mlp.down_proj.trellis', 'model.layers.8.mlp.up_proj.trellis', 'model.layers.14.self_attn.k_proj.SU', 'model.layers.12.mlp.up_proj.trellis', 'model.layers.31.mlp.down_proj.SV', 'model.layers.3.mlp.gate_proj.SV', 'model.layers.7.self_attn.k_proj.SU', 'model.layers.5.self_attn.o_proj.SV', 'model.layers.29.self_attn.k_proj.SU', 'model.layers.29.self_attn.k_proj.tlut', 'model.layers.4.mlp.up_proj.SU', 'model.layers.12.self_attn.k_proj.trellis', 'model.layers.17.mlp.down_proj.SU', 'model.layers.15.self_attn.k_proj.trellis', 'model.layers.23.mlp.down_proj.trellis', 'model.layers.16.mlp.up_proj.SU', 'model.layers.19.self_attn.q_proj.tlut', 'model.layers.2.mlp.down_proj.SV', 'model.layers.10.mlp.up_proj.tlut', 'model.layers.20.mlp.down_proj.SU', 'model.layers.6.mlp.up_proj.tlut', 'model.layers.17.self_attn.o_proj.SV', 'model.layers.19.self_attn.q_proj.SU', 'model.layers.15.mlp.down_proj.SU', 'model.layers.2.self_attn.o_proj.trellis', 'model.layers.21.self_attn.k_proj.tlut', 'model.layers.13.mlp.down_proj.tlut', 'model.layers.22.self_attn.v_proj.SV', 'model.layers.3.mlp.up_proj.SU', 'model.layers.17.self_attn.v_proj.tlut', 'model.layers.24.self_attn.k_proj.trellis', 'model.layers.25.self_attn.o_proj.tlut', 'model.layers.20.mlp.up_proj.SU', 'model.layers.7.mlp.up_proj.SV', 'model.layers.19.self_attn.q_proj.SV', 'model.layers.24.self_attn.k_proj.SU', 'model.layers.30.self_attn.k_proj.SV', 'model.layers.14.self_attn.o_proj.SU', 'model.layers.1.self_attn.o_proj.tlut', 'model.layers.27.self_attn.k_proj.SU', 'model.layers.23.mlp.gate_proj.tlut', 'model.layers.18.self_attn.k_proj.SU', 'model.layers.23.mlp.gate_proj.SV', 'model.layers.31.self_attn.k_proj.SV', 'model.layers.20.self_attn.o_proj.SV', 'model.layers.10.self_attn.k_proj.SU', 'model.layers.7.self_attn.o_proj.trellis', 'model.layers.5.self_attn.k_proj.trellis', 'model.layers.4.self_attn.q_proj.SV', 'model.layers.8.self_attn.q_proj.SV', 'model.layers.12.mlp.down_proj.SV', 'model.layers.14.self_attn.v_proj.SV', 'model.layers.7.self_attn.q_proj.tlut', 'model.layers.26.mlp.up_proj.tlut', 'model.layers.2.self_attn.o_proj.SU', 'model.layers.1.mlp.gate_proj.SU', 'model.layers.24.self_attn.v_proj.trellis', 'model.layers.12.mlp.gate_proj.tlut', 'model.layers.18.self_attn.k_proj.SV', 'model.layers.24.mlp.up_proj.trellis', 'model.layers.1.mlp.up_proj.SU', 'model.layers.17.mlp.up_proj.trellis', 'model.layers.12.self_attn.o_proj.tlut', 'model.layers.20.mlp.down_proj.SV', 'model.layers.26.mlp.down_proj.SV', 'model.layers.4.self_attn.q_proj.trellis', 'model.layers.9.self_attn.o_proj.tlut', 'model.layers.20.self_attn.o_proj.tlut', 'model.layers.22.mlp.down_proj.tlut', 'model.layers.25.mlp.gate_proj.SU', 'model.layers.14.self_attn.o_proj.trellis', 'model.layers.1.self_attn.k_proj.trellis', 'model.layers.15.mlp.up_proj.trellis', 'model.layers.6.self_attn.k_proj.SU', 'model.layers.20.self_attn.k_proj.trellis', 'model.layers.18.mlp.down_proj.tlut', 'model.layers.11.mlp.down_proj.trellis', 'model.layers.12.self_attn.q_proj.trellis', 'model.layers.13.self_attn.k_proj.SV', 'model.layers.21.mlp.up_proj.SU', 'model.layers.27.self_attn.o_proj.SU', 'model.layers.30.mlp.gate_proj.SU', 'model.layers.15.self_attn.v_proj.SV', 'model.layers.11.self_attn.o_proj.SV', 'model.layers.5.mlp.up_proj.trellis', 'model.layers.1.mlp.up_proj.tlut', 'model.layers.28.mlp.gate_proj.SU', 'model.layers.15.mlp.up_proj.tlut', 'model.layers.11.self_attn.v_proj.SV', 'model.layers.16.self_attn.k_proj.tlut', 'model.layers.2.mlp.down_proj.SU', 'model.layers.6.self_attn.o_proj.SU', 'model.layers.20.self_attn.o_proj.trellis', 'model.layers.1.self_attn.v_proj.trellis', 'model.layers.28.mlp.up_proj.SV', 'model.layers.13.self_attn.k_proj.tlut', 'model.layers.2.mlp.up_proj.SV', 'model.layers.25.mlp.up_proj.SV', 'model.layers.8.mlp.up_proj.tlut', 'model.layers.0.mlp.down_proj.SV', 'model.layers.18.self_attn.o_proj.SU', 'model.layers.2.self_attn.v_proj.tlut', 'model.layers.28.mlp.gate_proj.trellis', 'model.layers.12.self_attn.o_proj.trellis', 'model.layers.30.mlp.gate_proj.tlut', 'model.layers.22.self_attn.q_proj.tlut', 'model.layers.6.self_attn.o_proj.tlut', 'model.layers.22.mlp.gate_proj.SU', 'model.layers.7.mlp.down_proj.SU', 'model.layers.14.self_attn.q_proj.trellis', 'model.layers.18.mlp.up_proj.SV', 'model.layers.19.self_attn.v_proj.tlut', 'model.layers.29.self_attn.q_proj.tlut', 'model.layers.23.mlp.up_proj.SU', 'model.layers.13.self_attn.o_proj.tlut', 'model.layers.30.mlp.up_proj.SU', 'model.layers.0.self_attn.o_proj.tlut', 'model.layers.10.self_attn.q_proj.SV', 'model.layers.19.mlp.down_proj.SV', 'model.layers.10.mlp.down_proj.tlut', 'model.layers.27.mlp.down_proj.SU', 'model.layers.1.mlp.up_proj.trellis', 'model.layers.17.self_attn.q_proj.tlut', 'model.layers.3.self_attn.v_proj.tlut', 'model.layers.11.mlp.up_proj.SU', 'model.layers.17.mlp.up_proj.SV', 'model.layers.14.self_attn.o_proj.SV', 'model.layers.5.self_attn.v_proj.SV', 'model.layers.7.self_attn.q_proj.trellis', 'model.layers.26.self_attn.v_proj.trellis', 'model.layers.2.self_attn.v_proj.SV', 'model.layers.29.self_attn.v_proj.SV', 'model.layers.8.mlp.down_proj.tlut', 'model.layers.2.self_attn.o_proj.tlut', 'model.layers.0.mlp.down_proj.trellis', 'model.layers.0.self_attn.v_proj.tlut', 'model.layers.24.self_attn.v_proj.SV', 'model.layers.1.mlp.down_proj.tlut', 'model.layers.25.mlp.up_proj.trellis', 'model.layers.0.mlp.gate_proj.SV', 'model.layers.22.self_attn.v_proj.trellis', 'model.layers.15.mlp.down_proj.tlut', 'model.layers.27.mlp.down_proj.SV', 'model.layers.27.mlp.down_proj.trellis', 'model.layers.30.self_attn.v_proj.SV', 'model.layers.10.self_attn.v_proj.SV', 'model.layers.22.self_attn.v_proj.SU', 'model.layers.12.mlp.gate_proj.trellis', 'model.layers.6.mlp.gate_proj.SU', 'model.layers.5.self_attn.q_proj.trellis', 'model.layers.1.mlp.down_proj.trellis', 'model.layers.17.mlp.gate_proj.SV', 'model.layers.15.mlp.down_proj.trellis', 'model.layers.16.self_attn.o_proj.trellis', 'model.layers.31.self_attn.k_proj.trellis', 'model.layers.21.self_attn.k_proj.SV', 'model.layers.3.mlp.gate_proj.SU', 'model.layers.25.self_attn.o_proj.trellis', 'model.layers.26.self_attn.v_proj.tlut', 'model.layers.17.self_attn.o_proj.trellis', 'model.layers.13.self_attn.q_proj.SV', 'model.layers.26.self_attn.q_proj.trellis', 'model.layers.8.self_attn.k_proj.trellis', 'model.layers.4.self_attn.q_proj.tlut', 'model.layers.6.mlp.up_proj.SV', 'model.layers.2.self_attn.v_proj.SU', 'model.layers.23.self_attn.o_proj.trellis', 'model.layers.18.self_attn.v_proj.trellis', 'model.layers.6.self_attn.k_proj.SV', 'model.layers.15.self_attn.k_proj.SV', 'model.layers.15.self_attn.q_proj.tlut', 'model.layers.8.mlp.gate_proj.trellis', 'model.layers.29.self_attn.o_proj.SV', 'model.layers.21.mlp.down_proj.SU', 'model.layers.5.mlp.down_proj.trellis', 'model.layers.5.self_attn.k_proj.SU', 'model.layers.14.mlp.gate_proj.tlut', 'model.layers.9.self_attn.v_proj.SV', 'model.layers.31.mlp.up_proj.SU', 'model.layers.31.self_attn.o_proj.tlut', 'model.layers.15.self_attn.o_proj.tlut', 'model.layers.5.self_attn.q_proj.SU', 'model.layers.8.self_attn.o_proj.SV', 'model.layers.9.mlp.up_proj.trellis', 'model.layers.0.self_attn.q_proj.trellis', 'model.layers.14.self_attn.k_proj.trellis', 'model.layers.19.self_attn.o_proj.trellis', 'model.layers.11.self_attn.v_proj.tlut', 'model.layers.17.mlp.down_proj.trellis', 'model.layers.29.self_attn.q_proj.SU', 'model.layers.16.mlp.down_proj.SU', 'model.layers.26.self_attn.v_proj.SV', 'model.layers.6.self_attn.v_proj.tlut', 'model.layers.6.mlp.down_proj.tlut', 'model.layers.28.mlp.gate_proj.tlut', 'model.layers.16.mlp.up_proj.SV', 'model.layers.14.mlp.down_proj.SV', 'model.layers.11.self_attn.v_proj.trellis', 'model.layers.17.self_attn.o_proj.SU', 'model.layers.13.self_attn.v_proj.tlut', 'model.layers.27.mlp.gate_proj.SV', 'model.layers.0.mlp.up_proj.trellis', 'model.layers.25.self_attn.q_proj.tlut', 'model.layers.25.self_attn.k_proj.tlut', 'model.layers.30.mlp.up_proj.trellis', 'model.layers.4.self_attn.k_proj.trellis', 'model.layers.7.self_attn.v_proj.trellis', 'model.layers.21.self_attn.v_proj.SV', 'model.layers.13.self_attn.v_proj.SU', 'model.layers.14.mlp.down_proj.tlut', 'model.layers.3.self_attn.v_proj.SV', 'model.layers.3.self_attn.o_proj.trellis', 'model.layers.11.self_attn.k_proj.trellis', 'model.layers.0.mlp.up_proj.SV', 'model.layers.3.self_attn.o_proj.tlut', 'model.layers.1.mlp.gate_proj.SV', 'model.layers.30.mlp.gate_proj.SV', 'model.layers.1.mlp.down_proj.SV', 'model.layers.6.self_attn.q_proj.SU', 'model.layers.18.mlp.down_proj.trellis', 'model.layers.8.self_attn.o_proj.SU', 'model.layers.11.mlp.gate_proj.SV', 'model.layers.30.mlp.down_proj.SU', 'model.layers.30.self_attn.o_proj.trellis', 'model.layers.14.mlp.gate_proj.SV', 'model.layers.11.self_attn.q_proj.SU', 'model.layers.27.self_attn.o_proj.SV', 'model.layers.30.self_attn.v_proj.tlut', 'model.layers.29.mlp.up_proj.tlut', 'model.layers.5.self_attn.v_proj.SU', 'model.layers.22.mlp.up_proj.trellis', 'model.layers.15.mlp.gate_proj.tlut', 'model.layers.4.mlp.up_proj.trellis', 'model.layers.8.self_attn.v_proj.SV', 'model.layers.0.self_attn.q_proj.tlut', 'model.layers.1.self_attn.q_proj.SV', 'model.layers.2.mlp.down_proj.tlut', 'model.layers.2.self_attn.k_proj.trellis', 'model.layers.31.self_attn.v_proj.SU', 'model.layers.11.mlp.down_proj.tlut', 'model.layers.20.mlp.down_proj.tlut', 'model.layers.30.self_attn.o_proj.tlut', 'model.layers.2.mlp.gate_proj.SU', 'model.layers.24.mlp.up_proj.SV', 'model.layers.12.self_attn.k_proj.tlut', 'model.layers.22.mlp.gate_proj.trellis', 'model.layers.21.self_attn.v_proj.SU', 'model.layers.9.mlp.down_proj.tlut', 'model.layers.17.self_attn.k_proj.trellis', 'model.layers.27.self_attn.v_proj.SU', 'model.layers.12.mlp.down_proj.SU', 'model.layers.23.self_attn.o_proj.SU', 'model.layers.23.self_attn.q_proj.trellis', 'model.layers.9.self_attn.o_proj.SV', 'model.layers.23.mlp.up_proj.SV', 'model.layers.7.self_attn.o_proj.SU', 'model.layers.24.self_attn.k_proj.tlut', 'model.layers.20.self_attn.k_proj.SU', 'model.layers.31.self_attn.v_proj.trellis', 'model.layers.28.self_attn.k_proj.SU', 'model.layers.18.self_attn.o_proj.SV', 'model.layers.2.mlp.up_proj.trellis', 'model.layers.31.mlp.down_proj.SU', 'model.layers.23.self_attn.v_proj.SV', 'model.layers.18.self_attn.v_proj.SU', 'model.layers.5.mlp.gate_proj.trellis', 'model.layers.21.mlp.gate_proj.tlut', 'model.layers.21.self_attn.q_proj.tlut', 'model.layers.28.mlp.up_proj.trellis', 'model.layers.18.mlp.up_proj.SU', 'model.layers.9.self_attn.k_proj.SU', 'model.layers.0.self_attn.k_proj.trellis', 'model.layers.26.self_attn.k_proj.trellis', 'model.layers.17.mlp.gate_proj.trellis', 'model.layers.1.self_attn.k_proj.tlut', 'model.layers.10.mlp.up_proj.SU', 'model.layers.15.mlp.gate_proj.SV', 'model.layers.8.self_attn.k_proj.tlut', 'model.layers.9.self_attn.v_proj.trellis', 'model.layers.29.self_attn.k_proj.SV', 'model.layers.6.mlp.down_proj.SU', 'model.layers.19.self_attn.o_proj.SU', 'model.layers.19.mlp.up_proj.trellis', 'model.layers.31.mlp.gate_proj.SU', 'model.layers.25.mlp.down_proj.SV', 'model.layers.19.mlp.up_proj.SV', 'model.layers.2.mlp.down_proj.trellis', 'model.layers.28.self_attn.o_proj.tlut', 'model.layers.31.self_attn.o_proj.trellis', 'model.layers.9.self_attn.o_proj.trellis', 'model.layers.3.self_attn.o_proj.SV', 'model.layers.24.self_attn.q_proj.SV', 'model.layers.22.self_attn.o_proj.SU', 'model.layers.14.mlp.up_proj.SV', 'model.layers.3.self_attn.q_proj.trellis', 'model.layers.9.self_attn.q_proj.tlut', 'model.layers.4.self_attn.k_proj.tlut', 'model.layers.20.self_attn.v_proj.tlut', 'model.layers.31.mlp.up_proj.SV', 'model.layers.11.self_attn.q_proj.trellis', 'model.layers.8.mlp.gate_proj.SV', 'model.layers.21.mlp.up_proj.SV', 'model.layers.4.self_attn.k_proj.SU', 'model.layers.24.self_attn.v_proj.tlut', 'model.layers.0.self_attn.q_proj.SV', 'model.layers.1.self_attn.q_proj.SU', 'model.layers.10.self_attn.q_proj.tlut', 'model.layers.11.self_attn.q_proj.tlut', 'model.layers.14.self_attn.k_proj.SV', 'model.layers.28.self_attn.v_proj.tlut', 'model.layers.12.self_attn.o_proj.SV', 'model.layers.19.self_attn.k_proj.SU', 'model.layers.25.mlp.down_proj.tlut', 'model.layers.21.mlp.up_proj.tlut', 'model.layers.8.mlp.down_proj.SV', 'model.layers.17.mlp.gate_proj.tlut', 'model.layers.17.self_attn.q_proj.SV', 'model.layers.13.self_attn.o_proj.trellis', 'model.layers.9.mlp.down_proj.trellis', 'model.layers.24.self_attn.o_proj.trellis', 'model.layers.19.self_attn.v_proj.SV', 'model.layers.1.mlp.gate_proj.tlut', 'model.layers.22.mlp.up_proj.tlut', 'model.layers.23.mlp.down_proj.tlut', 'model.layers.6.self_attn.k_proj.tlut', 'model.layers.7.mlp.gate_proj.trellis', 'model.layers.22.self_attn.q_proj.SU', 'model.layers.9.mlp.up_proj.SU', 'model.layers.17.self_attn.k_proj.SV', 'model.layers.19.mlp.gate_proj.SU', 'model.layers.3.self_attn.q_proj.SU', 'model.layers.11.mlp.gate_proj.trellis', 'model.layers.30.mlp.down_proj.tlut', 'model.layers.2.mlp.up_proj.SU', 'model.layers.8.mlp.up_proj.SV', 'model.layers.21.mlp.down_proj.SV', 'model.layers.6.self_attn.v_proj.SU', 'model.layers.31.mlp.gate_proj.tlut', 'model.layers.29.mlp.gate_proj.SU', 'model.layers.4.mlp.down_proj.SV', 'model.layers.0.mlp.up_proj.tlut', 'model.layers.27.mlp.up_proj.SV', 'model.layers.28.self_attn.q_proj.SV', 'model.layers.10.self_attn.q_proj.trellis', 'model.layers.0.self_attn.k_proj.SU', 'model.layers.10.mlp.up_proj.trellis', 'model.layers.14.mlp.down_proj.SU', 'model.layers.29.self_attn.o_proj.SU', 'model.layers.16.mlp.gate_proj.SU', 'model.layers.3.mlp.up_proj.tlut', 'model.layers.28.self_attn.v_proj.SU', 'model.layers.6.self_attn.v_proj.trellis', 'model.layers.27.self_attn.q_proj.SV', 'model.layers.12.self_attn.v_proj.trellis', 'model.layers.24.mlp.gate_proj.SU', 'model.layers.15.self_attn.q_proj.trellis', 'model.layers.24.mlp.gate_proj.tlut', 'model.layers.2.self_attn.k_proj.SU', 'model.layers.8.self_attn.q_proj.SU', 'model.layers.8.self_attn.q_proj.tlut', 'model.layers.19.mlp.down_proj.trellis', 'model.layers.10.mlp.down_proj.SV', 'model.layers.28.mlp.down_proj.tlut', 'model.layers.18.mlp.gate_proj.trellis', 'model.layers.11.mlp.up_proj.tlut', 'model.layers.26.self_attn.v_proj.SU', 'model.layers.6.self_attn.k_proj.trellis', 'model.layers.6.self_attn.q_proj.trellis', 'model.layers.15.self_attn.v_proj.SU', 'model.layers.5.self_attn.o_proj.SU', 'model.layers.31.mlp.up_proj.trellis', 'model.layers.10.self_attn.k_proj.tlut', 'model.layers.23.self_attn.k_proj.tlut', 'model.layers.12.mlp.gate_proj.SV', 'model.layers.18.self_attn.v_proj.SV', 'model.layers.3.self_attn.k_proj.SV', 'model.layers.0.mlp.gate_proj.trellis', 'model.layers.28.self_attn.o_proj.trellis', 'model.layers.15.self_attn.v_proj.tlut', 'model.layers.23.self_attn.v_proj.trellis', 'model.layers.21.self_attn.o_proj.SU', 'model.layers.20.self_attn.q_proj.tlut', 'model.layers.27.self_attn.q_proj.tlut', 'model.layers.31.self_attn.o_proj.SV', 'model.layers.19.self_attn.q_proj.trellis', 'model.layers.18.self_attn.o_proj.trellis', 'model.layers.30.self_attn.q_proj.tlut', 'model.layers.29.self_attn.v_proj.tlut', 'model.layers.8.mlp.down_proj.trellis', 'model.layers.10.mlp.gate_proj.trellis', 'model.layers.14.self_attn.v_proj.trellis', 'model.layers.31.self_attn.o_proj.SU', 'model.layers.24.mlp.up_proj.SU', 'model.layers.22.mlp.down_proj.SV', 'model.layers.16.self_attn.k_proj.SV', 'model.layers.17.mlp.gate_proj.SU', 'model.layers.26.self_attn.o_proj.tlut', 'model.layers.16.self_attn.q_proj.SV', 'model.layers.22.self_attn.q_proj.trellis', 'model.layers.11.mlp.down_proj.SU', 'model.layers.23.self_attn.k_proj.trellis', 'model.layers.9.mlp.down_proj.SV', 'model.layers.12.mlp.up_proj.tlut', 'model.layers.26.self_attn.k_proj.SU', 'model.layers.18.self_attn.o_proj.tlut', 'model.layers.28.self_attn.o_proj.SU', 'model.layers.12.self_attn.q_proj.SU', 'model.layers.1.mlp.up_proj.SV', 'model.layers.15.self_attn.k_proj.SU', 'model.layers.16.mlp.gate_proj.trellis', 'model.layers.3.self_attn.q_proj.SV', 'model.layers.8.self_attn.k_proj.SU', 'model.layers.9.mlp.up_proj.SV', 'model.layers.22.mlp.gate_proj.tlut', 'model.layers.4.self_attn.o_proj.SV', 'model.layers.13.self_attn.o_proj.SU', 'model.layers.9.self_attn.q_proj.SV', 'model.layers.28.self_attn.o_proj.SV', 'model.layers.0.self_attn.o_proj.SU', 'model.layers.17.self_attn.k_proj.SU', 'model.layers.27.mlp.up_proj.trellis', 'model.layers.21.mlp.down_proj.tlut', 'model.layers.24.mlp.up_proj.tlut', 'model.layers.27.mlp.down_proj.tlut', 'model.layers.29.mlp.gate_proj.tlut', 'model.layers.4.mlp.gate_proj.SV', 'model.layers.6.mlp.gate_proj.trellis', 'model.layers.27.self_attn.v_proj.trellis', 'model.layers.12.mlp.up_proj.SU', 'model.layers.20.mlp.gate_proj.trellis', 'model.layers.24.self_attn.k_proj.SV', 'model.layers.18.self_attn.q_proj.tlut', 'model.layers.9.self_attn.k_proj.trellis', 'model.layers.20.self_attn.k_proj.tlut', 'model.layers.29.mlp.gate_proj.SV', 'model.layers.24.mlp.down_proj.trellis', 'model.layers.10.self_attn.o_proj.SV', 'model.layers.26.mlp.down_proj.trellis', 'model.layers.17.self_attn.q_proj.SU', 'model.layers.5.self_attn.v_proj.trellis', 'model.layers.14.self_attn.o_proj.tlut', 'model.layers.23.self_attn.o_proj.SV', 'model.layers.12.self_attn.q_proj.tlut', 'model.layers.12.self_attn.v_proj.tlut', 'model.layers.14.mlp.down_proj.trellis', 'model.layers.19.mlp.gate_proj.tlut', 'model.layers.23.self_attn.k_proj.SV', 'model.layers.25.self_attn.k_proj.trellis', 'model.layers.18.mlp.gate_proj.SU', 'model.layers.25.self_attn.o_proj.SU', 'model.layers.28.mlp.up_proj.SU', 'model.layers.21.self_attn.v_proj.trellis', 'model.layers.19.self_attn.o_proj.SV', 'model.layers.23.self_attn.k_proj.SU', 'model.layers.25.mlp.up_proj.tlut', 'model.layers.5.mlp.down_proj.SV', 'model.layers.14.self_attn.q_proj.SU', 'model.layers.19.mlp.up_proj.tlut', 'model.layers.16.self_attn.v_proj.tlut', 'model.layers.17.mlp.down_proj.tlut', 'model.layers.19.mlp.gate_proj.SV', 'model.layers.26.mlp.down_proj.tlut', 'model.layers.26.self_attn.q_proj.SV', 'model.layers.25.self_attn.v_proj.trellis', 'model.layers.27.mlp.gate_proj.SU', 'model.layers.30.self_attn.o_proj.SU', 'model.layers.28.mlp.up_proj.tlut', 'model.layers.25.self_attn.q_proj.trellis', 'model.layers.12.mlp.up_proj.SV', 'model.layers.20.mlp.gate_proj.tlut', 'model.layers.3.self_attn.k_proj.trellis', 'model.layers.13.self_attn.q_proj.SU', 'model.layers.15.self_attn.o_proj.SU', 'model.layers.25.self_attn.q_proj.SU', 'model.layers.11.mlp.down_proj.SV', 'model.layers.2.self_attn.k_proj.tlut', 'model.layers.16.mlp.down_proj.tlut', 'model.layers.30.self_attn.o_proj.SV', 'model.layers.26.mlp.up_proj.trellis', 'model.layers.2.mlp.up_proj.tlut', 'model.layers.3.mlp.gate_proj.trellis', 'model.layers.7.self_attn.k_proj.trellis', 'model.layers.19.mlp.down_proj.SU', 'model.layers.26.self_attn.q_proj.SU', 'model.layers.14.mlp.up_proj.tlut', 'model.layers.5.self_attn.k_proj.SV', 'model.layers.20.self_attn.q_proj.SU', 'model.layers.12.self_attn.q_proj.SV', 'model.layers.0.mlp.up_proj.SU', 'model.layers.10.mlp.up_proj.SV', 'model.layers.20.mlp.up_proj.tlut', 'model.layers.7.self_attn.q_proj.SV', 'model.layers.1.self_attn.o_proj.SV', 'model.layers.27.self_attn.k_proj.trellis', 'model.layers.7.self_attn.k_proj.tlut', 'model.layers.22.self_attn.q_proj.SV', 'model.layers.26.mlp.gate_proj.SV', 'model.layers.17.mlp.up_proj.tlut', 'model.layers.13.self_attn.o_proj.SV', 'model.layers.22.self_attn.o_proj.SV', 'model.layers.4.mlp.down_proj.tlut', 'model.layers.0.mlp.gate_proj.tlut', 'model.layers.23.self_attn.q_proj.SV', 'model.layers.31.self_attn.q_proj.SU', 'model.layers.19.self_attn.v_proj.SU', 'model.layers.29.self_attn.v_proj.trellis', 'model.layers.31.self_attn.v_proj.tlut', 'model.layers.17.self_attn.q_proj.trellis', 'model.layers.23.self_attn.o_proj.tlut', 'model.layers.20.self_attn.v_proj.trellis', 'model.layers.24.mlp.gate_proj.trellis', 'model.layers.1.self_attn.v_proj.SU', 'model.layers.31.mlp.down_proj.tlut', 'model.layers.23.mlp.down_proj.SV', 'model.layers.25.self_attn.v_proj.SU', 'model.layers.9.mlp.down_proj.SU', 'model.layers.3.self_attn.o_proj.SU', 'model.layers.25.self_attn.k_proj.SU', 'model.layers.25.mlp.gate_proj.SV', 'model.layers.6.self_attn.o_proj.trellis', 'model.layers.21.self_attn.k_proj.SU', 'model.layers.29.self_attn.q_proj.trellis', 'model.layers.6.mlp.down_proj.trellis', 'model.layers.10.self_attn.o_proj.tlut', 'model.layers.15.mlp.up_proj.SU', 'model.layers.6.mlp.gate_proj.SV', 'model.layers.15.self_attn.o_proj.SV', 'model.layers.7.mlp.down_proj.trellis', 'model.layers.13.mlp.down_proj.SU', 'model.layers.0.mlp.down_proj.SU', 'model.layers.16.self_attn.v_proj.trellis', 'model.layers.26.self_attn.k_proj.tlut', 'model.layers.6.self_attn.q_proj.SV', 'model.layers.9.mlp.up_proj.tlut', 'model.layers.11.self_attn.o_proj.trellis', 'model.layers.4.self_attn.o_proj.SU', 'model.layers.29.self_attn.q_proj.SV', 'model.layers.14.mlp.up_proj.trellis', 'model.layers.25.self_attn.v_proj.tlut', 'model.layers.20.mlp.up_proj.trellis', 'model.layers.12.mlp.down_proj.tlut', 'model.layers.11.mlp.up_proj.SV', 'model.layers.27.self_attn.o_proj.tlut', 'model.layers.13.self_attn.q_proj.trellis', 'model.layers.16.self_attn.o_proj.SU', 'model.layers.3.mlp.up_proj.trellis', 'model.layers.2.self_attn.q_proj.tlut', 'model.layers.30.self_attn.k_proj.SU', 'model.layers.0.self_attn.v_proj.SU', 'model.layers.24.mlp.down_proj.SV', 'model.layers.26.self_attn.o_proj.trellis', 'model.layers.31.mlp.up_proj.tlut', 'model.layers.11.self_attn.k_proj.tlut', 'model.layers.9.mlp.gate_proj.SV', 'model.layers.24.self_attn.q_proj.SU', 'model.layers.3.mlp.down_proj.tlut', 'model.layers.27.self_attn.v_proj.SV', 'model.layers.12.self_attn.v_proj.SV', 'model.layers.16.self_attn.q_proj.SU', 'model.layers.29.mlp.up_proj.trellis', 'model.layers.10.self_attn.v_proj.SU', 'model.layers.27.self_attn.q_proj.SU', 'model.layers.12.self_attn.k_proj.SU', 'model.layers.28.self_attn.v_proj.trellis', 'model.layers.5.self_attn.q_proj.tlut', 'model.layers.8.mlp.gate_proj.SU', 'model.layers.14.self_attn.v_proj.tlut', 'model.layers.5.self_attn.o_proj.tlut', 'model.layers.21.mlp.up_proj.trellis', 'model.layers.4.self_attn.v_proj.tlut', 'model.layers.22.self_attn.o_proj.trellis', 'model.layers.10.self_attn.v_proj.tlut', 'model.layers.20.self_attn.k_proj.SV', 'model.layers.10.mlp.gate_proj.SV', 'model.layers.1.self_attn.v_proj.tlut'}\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at relaxml/Llama-3.1-8B-Instruct-QTIP-2Bit and are newly initialized: ['model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/217 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e58e100f2f243cdb0a5b0f68a2beb02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "370128acb0874618aa653dfc4bafd4df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10debea8f0f94f88b546d4c6d0fb045a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Generate a Python function that calculates the area of a rectangle given its length and width.\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful chatbot who always responds in polite manner!\"},\n",
        "    {\"role\": \"user\", \"content\": prompt},\n",
        "]\n",
        "outputs = pipeline(\n",
        "    messages,\n",
        "    max_new_tokens=22,\n",
        ")\n",
        "text = outputs[0][\"generated_text\"][-1]\n",
        "print(text['content'])\n",
        "print(\"Setting 'pad_token_id' to 'eos_token_id': None for open-end generation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Xp4ijMxo0GO_",
        "outputId": "a89a03e0-ac6f-4b88-ddbb-7bdc4a6470bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-cca30ad30f86>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m ]\n\u001b[0;32m----> 9\u001b[0;31m outputs = pipeline(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                     \u001b[0mchats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mChat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 🐈 🐈 🐈\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m             )\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, prompt_text, prefix, handle_long_generation, add_special_tokens, truncation, padding, max_length, continue_final_message, **generate_kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_final_message\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mcontinue_final_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             inputs = self.tokenizer.apply_chat_template(\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0mprompt_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0madd_generation_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mcontinue_final_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mapply_chat_template\u001b[0;34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0mtokenizer_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         \u001b[0mchat_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chat_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_assistant_tokens_mask\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\{\\%-?\\s*generation\\s*-?\\%\\}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchat_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mget_chat_template\u001b[0;34m(self, chat_template, tools)\u001b[0m\n\u001b[1;32m   1787\u001b[0m                 \u001b[0mchat_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1790\u001b[0m                     \u001b[0;34m\"Cannot use chat template functions because tokenizer.chat_template is not set and no template \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                     \u001b[0;34m\"argument was passed! For information about writing templates and setting the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Generate a Python function that calculates the area of a rectangle given its length and width.\n",
        "\"\"\"\n",
        "\n",
        "# Instead of messages, provide the prompt directly\n",
        "output = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=22,\n",
        ")\n",
        "\n",
        "# Access the generated text\n",
        "generated_text = output[0]['generated_text']\n",
        "print(generated_text)\n",
        "print(\"Setting 'pad_token_id' to 'eos_token_id': None for open-end generation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqaCfoy81Xwn",
        "outputId": "573fbce0-a1f2-45e4-8bdc-20a10c5643c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generate a Python function that calculates the area of a rectangle given its length and width.\n",
            " huz NONINFRINGEMENTESSAGES Kroměัตรbuilders@qqOptionsMenu huzonoricester_TestCase\\View NONINFRINGEMENTESSAGES주의onor huzonorOptionsMenu� NONINFRINGEMENT\n",
            "Setting 'pad_token_id' to 'eos_token_id': None for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "who is ai?\n",
        "\"\"\"\n",
        "\n",
        "# Instead of messages, provide the prompt directly\n",
        "output = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=22,\n",
        ")\n",
        "\n",
        "# Access the generated text\n",
        "generated_text = output[0]['generated_text']\n",
        "print(generated_text)\n",
        "print(\"Setting 'pad_token_id' to 'eos_token_id': None for open-end generation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2PQuuEE2eho",
        "outputId": "a63b5214-480d-4509-d80d-27c43c120a79"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "who is ai?\n",
            "_Stream huz Kroměátebuilders NONINFRINGEMENT huz Kromě huz huz huz huzrowable huz.Cryptography huzeringering Kromě주의.Cryptography huz\n",
            "Setting 'pad_token_id' to 'eos_token_id': None for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = outputs[0][\"generated_text\"][-1]\n",
        "print(text['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "mXZOyc6127qo",
        "outputId": "bcd5cd55-8594-472f-d6d7-82f0cc520fce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'outputs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-815f921b6fa1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generated_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Generate a Python function that calculates the area of a rectangle given its length and width.\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful chatbot who always responds in polite manner!\"},\n",
        "    {\"role\": \"user\", \"content\": prompt},\n",
        "]\n",
        "outputs = pipeline(\n",
        "    messages,\n",
        "    max_new_tokens=22,\n",
        ")\n",
        "text = outputs[0][\"generated_text\"][-1]\n",
        "print(text['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "P990gv_13auo",
        "outputId": "a5848e81-41ab-4b19-b9e2-7c06fed8e55b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4543f2339b43>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m ]\n\u001b[0;32m----> 9\u001b[0;31m outputs = pipeline(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                     \u001b[0mchats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mChat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 🐈 🐈 🐈\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m             )\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, prompt_text, prefix, handle_long_generation, add_special_tokens, truncation, padding, max_length, continue_final_message, **generate_kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_final_message\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mcontinue_final_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             inputs = self.tokenizer.apply_chat_template(\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0mprompt_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0madd_generation_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mcontinue_final_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mapply_chat_template\u001b[0;34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0mtokenizer_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         \u001b[0mchat_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chat_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_assistant_tokens_mask\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\{\\%-?\\s*generation\\s*-?\\%\\}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchat_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mget_chat_template\u001b[0;34m(self, chat_template, tools)\u001b[0m\n\u001b[1;32m   1787\u001b[0m                 \u001b[0mchat_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1790\u001b[0m                     \u001b[0;34m\"Cannot use chat template functions because tokenizer.chat_template is not set and no template \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                     \u001b[0;34m\"argument was passed! For information about writing templates and setting the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9FtcA51j3mvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O0DJHIyx3msX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_id = \"relaxml/Llama-3.1-8B-Instruct-QTIP-2Bit\"\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "prompt = \"\"\"\n",
        "Generate a Python function that calculates the area of a rectangle given its length and width.\n",
        "\"\"\"\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,  # Pass the prompt directly as a string\n",
        "    max_new_tokens=256,\n",
        ")\n",
        "text = outputs[0][\"generated_text\"]\n",
        "print(text)\n",
        "print(\"Setting 'pad_token_id' to 'eos_token_id': None for open-end generation.\")"
      ],
      "metadata": {
        "id": "anQaB_QM3mpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Generate a Python function that calculates the area of a rectangle given its length and width.\n",
        "\"\"\"\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,  # Pass the prompt directly as a string\n",
        "    max_new_tokens=22,\n",
        ")\n",
        "text = outputs[0][\"generated_text\"]\n",
        "print(text)\n",
        "print(\"Setting 'pad_token_id' to 'eos_token_id': None for open-end generation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JDvjYv_3tIp",
        "outputId": "ac8e9885-0492-4bf0-b512-b605b2d6ad73"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generate a Python function that calculates the area of a rectangle given its length and width.\n",
            "rvine Berrymistodie� eiusmod huzrvine� �주의 huzarumistavingmistonorัตร-lndัตรILLSัตร\n",
            "Setting 'pad_token_id' to 'eos_token_id': None for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_id = \"relaxml/Llama-3.1-8B-Instruct-QTIP-2Bit\"\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "prompt = \"\"\"\n",
        "Generate a Python function that calculates the area of a rectangle given its length and width.\n",
        "\"\"\"\n",
        "\n",
        "# Instead of messages, provide the prompt directly\n",
        "output = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=22,\n",
        ")\n",
        "\n",
        "# Access the generated text\n",
        "generated_text = output[0]['generated_text']\n",
        "print(generated_text)\n",
        "print(\"Setting 'pad_token_id' to 'eos_token_id': None for open-end generation.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "DxyKX48p1ZK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdZrF1ln5Epx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dh4ctB3I5Eka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_id = \"relaxml/Llama-3.1-8B-Instruct-QTIP-2Bit\"\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Option 1: Use a custom chat template\n",
        "tokenizer = pipeline.tokenizer\n",
        "tokenizer.chat_template = \"{% for message in messages %}\\n{% if message['role'] == 'system' %}\\n<|system|>\\n{{ message['content'] }}\\n{% elif message['role'] == 'user' %}\\n<|user|>\\n{{ message['content'] }}\\n{% elif message['role'] == 'assistant' %}\\n<|assistant|>\\n{{ message['content'] }}\\n{% endif %}\\n{% endfor %}\\n{% if add_generation_prompt %}\\n<|assistant|>\\n{% endif %}\"\n",
        "\n",
        "# OR Option 2: Format the prompt manually instead of using messages\n",
        "prompt = \"\"\"<|system|>\n",
        "You are a helpful chatbot who always responds in polite manner!\n",
        "<|user|>\n",
        "Generate a Python function that calculates the area of a rectangle given its length and width.\n",
        "<|assistant|>\"\"\"\n",
        "\n",
        "# If using Option 1 with messages:\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful chatbot who always responds in polite manner!\"},\n",
        "    {\"role\": \"user\", \"content\": \"Generate a Python function that calculates the area of a rectangle given its length and width.\"},\n",
        "]\n",
        "outputs = pipeline(\n",
        "    messages,\n",
        "    max_new_tokens=256,  # Increased token count to get a complete response\n",
        ")\n",
        "\n",
        "# If using Option 2 with manual formatting:\n",
        "# outputs = pipeline(\n",
        "#     prompt,\n",
        "#     max_new_tokens=256,\n",
        "# )\n",
        "\n",
        "# Print the generated response\n",
        "if isinstance(outputs[0][\"generated_text\"], list):\n",
        "    # For message-based output\n",
        "    print(outputs[0][\"generated_text\"][-1][\"content\"])\n",
        "else:\n",
        "    # For text-based output\n",
        "    generated_text = outputs[0][\"generated_text\"]\n",
        "    # Extract just the assistant's response\n",
        "    assistant_response = generated_text.split(\"<|assistant|>\")[-1].strip()\n",
        "    print(assistant_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "i9p1bHMq5EhJ",
        "outputId": "68a450ec-11d6-437e-c2ee-49cf68e11073"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at relaxml/Llama-3.1-8B-Instruct-QTIP-2Bit were not used when initializing LlamaForCausalLM: {'model.layers.7.self_attn.q_proj.SV', 'model.layers.11.self_attn.k_proj.trellis', 'model.layers.15.mlp.gate_proj.SU', 'model.layers.20.mlp.gate_proj.SU', 'model.layers.6.mlp.gate_proj.tlut', 'model.layers.28.self_attn.k_proj.tlut', 'model.layers.7.mlp.up_proj.tlut', 'model.layers.5.self_attn.k_proj.SV', 'model.layers.19.self_attn.v_proj.tlut', 'model.layers.10.mlp.down_proj.SU', 'model.layers.7.mlp.down_proj.SV', 'model.layers.16.self_attn.v_proj.SU', 'model.layers.2.mlp.gate_proj.SU', 'model.layers.9.mlp.up_proj.SU', 'model.layers.13.mlp.gate_proj.trellis', 'model.layers.5.self_attn.k_proj.trellis', 'model.layers.0.mlp.up_proj.tlut', 'model.layers.5.self_attn.q_proj.trellis', 'model.layers.23.mlp.gate_proj.SV', 'model.layers.25.mlp.up_proj.SV', 'model.layers.26.self_attn.v_proj.SU', 'model.layers.31.self_attn.k_proj.trellis', 'model.layers.7.self_attn.v_proj.SU', 'model.layers.15.mlp.up_proj.trellis', 'model.layers.7.self_attn.k_proj.trellis', 'model.layers.7.mlp.gate_proj.trellis', 'model.layers.7.self_attn.q_proj.SU', 'model.layers.11.self_attn.o_proj.SV', 'model.layers.31.self_attn.k_proj.SU', 'model.layers.26.mlp.up_proj.trellis', 'model.layers.6.self_attn.q_proj.trellis', 'model.layers.30.self_attn.o_proj.SV', 'model.layers.4.self_attn.q_proj.SU', 'model.layers.27.mlp.up_proj.SU', 'model.layers.30.self_attn.k_proj.tlut', 'model.layers.15.mlp.up_proj.SV', 'model.layers.18.self_attn.o_proj.SV', 'model.layers.8.mlp.down_proj.SU', 'model.layers.26.mlp.down_proj.SV', 'model.layers.16.mlp.up_proj.SU', 'model.layers.0.self_attn.k_proj.SV', 'model.layers.2.self_attn.o_proj.SV', 'model.layers.6.mlp.up_proj.trellis', 'model.layers.25.self_attn.v_proj.SU', 'model.layers.13.mlp.gate_proj.SU', 'model.layers.5.self_attn.o_proj.trellis', 'model.layers.13.mlp.gate_proj.SV', 'model.layers.28.mlp.gate_proj.tlut', 'model.layers.30.self_attn.v_proj.SU', 'model.layers.11.self_attn.q_proj.SU', 'model.layers.19.mlp.up_proj.tlut', 'model.layers.26.mlp.down_proj.tlut', 'model.layers.15.mlp.gate_proj.trellis', 'model.layers.0.self_attn.o_proj.trellis', 'model.layers.14.self_attn.o_proj.trellis', 'model.layers.19.self_attn.q_proj.SV', 'model.layers.14.mlp.gate_proj.SV', 'model.layers.29.self_attn.k_proj.SV', 'model.layers.4.self_attn.k_proj.tlut', 'model.layers.14.mlp.down_proj.tlut', 'model.layers.16.mlp.gate_proj.tlut', 'model.layers.24.mlp.down_proj.tlut', 'model.layers.2.mlp.gate_proj.SV', 'model.layers.17.self_attn.q_proj.tlut', 'model.layers.30.self_attn.o_proj.trellis', 'model.layers.31.mlp.gate_proj.trellis', 'model.layers.12.mlp.up_proj.tlut', 'model.layers.28.self_attn.o_proj.tlut', 'model.layers.3.mlp.down_proj.SV', 'model.layers.18.self_attn.v_proj.SV', 'model.layers.0.self_attn.v_proj.trellis', 'model.layers.16.self_attn.v_proj.SV', 'model.layers.0.self_attn.q_proj.trellis', 'model.layers.29.mlp.down_proj.SV', 'model.layers.31.self_attn.o_proj.SV', 'model.layers.27.mlp.up_proj.SV', 'model.layers.28.self_attn.v_proj.SV', 'model.layers.25.mlp.up_proj.tlut', 'model.layers.31.self_attn.q_proj.SU', 'model.layers.11.mlp.up_proj.SU', 'model.layers.11.self_attn.o_proj.SU', 'model.layers.15.mlp.up_proj.tlut', 'model.layers.4.self_attn.v_proj.SU', 'model.layers.6.self_attn.v_proj.tlut', 'model.layers.7.self_attn.v_proj.tlut', 'model.layers.3.self_attn.v_proj.trellis', 'model.layers.9.mlp.gate_proj.SU', 'model.layers.30.mlp.gate_proj.SU', 'model.layers.16.mlp.down_proj.tlut', 'model.layers.19.self_attn.v_proj.SV', 'model.layers.31.self_attn.v_proj.tlut', 'model.layers.8.self_attn.o_proj.trellis', 'model.layers.3.mlp.up_proj.tlut', 'model.layers.0.mlp.gate_proj.tlut', 'model.layers.27.self_attn.o_proj.trellis', 'model.layers.29.self_attn.v_proj.tlut', 'model.layers.5.self_attn.k_proj.SU', 'model.layers.19.self_attn.o_proj.SU', 'model.layers.27.self_attn.k_proj.SV', 'model.layers.28.self_attn.o_proj.SU', 'model.layers.4.self_attn.k_proj.SV', 'model.layers.14.mlp.up_proj.trellis', 'model.layers.21.mlp.up_proj.tlut', 'model.layers.15.self_attn.o_proj.SV', 'model.layers.25.mlp.up_proj.SU', 'model.layers.3.self_attn.v_proj.SU', 'model.layers.10.mlp.gate_proj.SU', 'model.layers.14.mlp.down_proj.SV', 'model.layers.3.mlp.gate_proj.SV', 'model.layers.23.self_attn.k_proj.SU', 'model.layers.2.self_attn.v_proj.SU', 'model.layers.24.self_attn.v_proj.SU', 'model.layers.9.mlp.down_proj.SV', 'model.layers.6.self_attn.k_proj.SU', 'model.layers.5.mlp.gate_proj.trellis', 'model.layers.15.mlp.gate_proj.SV', 'model.layers.22.self_attn.q_proj.trellis', 'model.layers.0.self_attn.o_proj.SU', 'model.layers.11.self_attn.o_proj.trellis', 'model.layers.4.mlp.down_proj.tlut', 'model.layers.31.mlp.up_proj.tlut', 'model.layers.21.self_attn.o_proj.SV', 'model.layers.0.mlp.gate_proj.trellis', 'model.layers.29.mlp.down_proj.SU', 'model.layers.21.mlp.gate_proj.trellis', 'model.layers.29.self_attn.k_proj.tlut', 'model.layers.31.mlp.up_proj.trellis', 'model.layers.18.self_attn.q_proj.trellis', 'model.layers.11.self_attn.v_proj.SV', 'model.layers.16.self_attn.q_proj.SU', 'model.layers.18.mlp.down_proj.SV', 'model.layers.21.mlp.up_proj.trellis', 'model.layers.3.mlp.up_proj.SV', 'model.layers.5.self_attn.o_proj.SV', 'model.layers.9.self_attn.v_proj.SV', 'model.layers.3.self_attn.o_proj.trellis', 'model.layers.14.self_attn.q_proj.trellis', 'model.layers.0.self_attn.v_proj.tlut', 'model.layers.2.mlp.up_proj.SV', 'model.layers.26.self_attn.k_proj.trellis', 'model.layers.27.self_attn.o_proj.SV', 'model.layers.8.self_attn.v_proj.SV', 'model.layers.27.self_attn.v_proj.SU', 'model.layers.21.mlp.up_proj.SU', 'model.layers.14.self_attn.k_proj.SU', 'model.layers.15.mlp.gate_proj.tlut', 'model.layers.10.mlp.down_proj.tlut', 'model.layers.11.mlp.gate_proj.SU', 'model.layers.13.mlp.up_proj.tlut', 'model.layers.24.mlp.up_proj.SU', 'model.layers.15.self_attn.k_proj.SU', 'model.layers.15.self_attn.q_proj.tlut', 'model.layers.18.self_attn.q_proj.tlut', 'model.layers.26.self_attn.o_proj.SU', 'model.layers.11.self_attn.v_proj.SU', 'model.layers.27.mlp.down_proj.tlut', 'model.layers.1.mlp.down_proj.SU', 'model.layers.0.self_attn.o_proj.tlut', 'model.layers.8.self_attn.v_proj.SU', 'model.layers.11.mlp.gate_proj.tlut', 'model.layers.31.mlp.down_proj.trellis', 'model.layers.20.self_attn.q_proj.tlut', 'model.layers.20.mlp.gate_proj.trellis', 'model.layers.12.self_attn.o_proj.SU', 'model.layers.13.mlp.gate_proj.tlut', 'model.layers.10.self_attn.q_proj.SU', 'model.layers.10.mlp.up_proj.trellis', 'model.layers.23.self_attn.q_proj.SV', 'model.layers.8.mlp.gate_proj.SU', 'model.layers.20.mlp.down_proj.trellis', 'model.layers.3.self_attn.k_proj.SV', 'model.layers.20.mlp.down_proj.SU', 'model.layers.26.self_attn.o_proj.trellis', 'model.layers.3.self_attn.k_proj.tlut', 'model.layers.25.self_attn.k_proj.tlut', 'model.layers.31.self_attn.k_proj.SV', 'model.layers.14.self_attn.o_proj.tlut', 'model.layers.2.self_attn.q_proj.tlut', 'model.layers.5.self_attn.o_proj.tlut', 'model.layers.30.self_attn.v_proj.SV', 'model.layers.19.self_attn.v_proj.trellis', 'model.layers.4.self_attn.k_proj.trellis', 'model.layers.26.self_attn.v_proj.SV', 'model.layers.14.mlp.gate_proj.trellis', 'model.layers.29.self_attn.k_proj.SU', 'model.layers.14.mlp.up_proj.tlut', 'model.layers.3.mlp.down_proj.SU', 'model.layers.23.self_attn.k_proj.trellis', 'model.layers.27.self_attn.q_proj.trellis', 'model.layers.6.mlp.down_proj.trellis', 'model.layers.8.self_attn.k_proj.SU', 'model.layers.20.self_attn.o_proj.trellis', 'model.layers.22.self_attn.q_proj.SV', 'model.layers.11.mlp.up_proj.SV', 'model.layers.6.self_attn.o_proj.trellis', 'model.layers.22.self_attn.q_proj.SU', 'model.layers.1.mlp.up_proj.tlut', 'model.layers.4.mlp.gate_proj.tlut', 'model.layers.30.self_attn.k_proj.SV', 'model.layers.28.mlp.up_proj.tlut', 'model.layers.17.self_attn.o_proj.SU', 'model.layers.22.mlp.gate_proj.tlut', 'model.layers.25.mlp.gate_proj.trellis', 'model.layers.24.mlp.gate_proj.trellis', 'model.layers.20.mlp.up_proj.tlut', 'model.layers.21.mlp.down_proj.SV', 'model.layers.26.self_attn.v_proj.tlut', 'model.layers.22.mlp.up_proj.tlut', 'model.layers.19.self_attn.o_proj.tlut', 'model.layers.26.mlp.gate_proj.tlut', 'model.layers.9.self_attn.q_proj.SU', 'model.layers.13.self_attn.k_proj.SV', 'model.layers.8.self_attn.v_proj.tlut', 'model.layers.24.self_attn.k_proj.SV', 'model.layers.2.mlp.down_proj.trellis', 'model.layers.6.mlp.down_proj.SV', 'model.layers.8.mlp.up_proj.SV', 'model.layers.10.mlp.up_proj.tlut', 'model.layers.21.self_attn.o_proj.trellis', 'model.layers.18.mlp.down_proj.trellis', 'model.layers.25.self_attn.q_proj.SU', 'model.layers.4.mlp.down_proj.SU', 'model.layers.24.mlp.gate_proj.tlut', 'model.layers.22.mlp.gate_proj.SV', 'model.layers.6.mlp.gate_proj.SU', 'model.layers.11.mlp.down_proj.SU', 'model.layers.25.self_attn.o_proj.SU', 'model.layers.5.mlp.up_proj.SU', 'model.layers.9.mlp.down_proj.trellis', 'model.layers.1.mlp.gate_proj.tlut', 'model.layers.9.mlp.gate_proj.tlut', 'model.layers.27.mlp.down_proj.SV', 'model.layers.29.self_attn.v_proj.trellis', 'model.layers.20.mlp.up_proj.trellis', 'model.layers.11.mlp.gate_proj.trellis', 'model.layers.8.self_attn.k_proj.trellis', 'model.layers.24.mlp.up_proj.SV', 'model.layers.14.self_attn.k_proj.tlut', 'model.layers.27.mlp.gate_proj.trellis', 'model.layers.24.self_attn.o_proj.SU', 'model.layers.6.self_attn.q_proj.SU', 'model.layers.0.self_attn.o_proj.SV', 'model.layers.17.mlp.up_proj.trellis', 'model.layers.31.mlp.down_proj.tlut', 'model.layers.7.self_attn.v_proj.trellis', 'model.layers.22.mlp.up_proj.SV', 'model.layers.3.self_attn.o_proj.SU', 'model.layers.20.self_attn.v_proj.trellis', 'model.layers.3.self_attn.o_proj.SV', 'model.layers.14.self_attn.v_proj.tlut', 'model.layers.31.self_attn.o_proj.tlut', 'model.layers.18.self_attn.o_proj.SU', 'model.layers.23.self_attn.o_proj.trellis', 'model.layers.31.self_attn.o_proj.SU', 'model.layers.6.mlp.up_proj.SU', 'model.layers.29.self_attn.o_proj.trellis', 'model.layers.8.self_attn.k_proj.SV', 'model.layers.9.self_attn.k_proj.tlut', 'model.layers.2.mlp.down_proj.SU', 'model.layers.13.self_attn.o_proj.SU', 'model.layers.23.mlp.up_proj.trellis', 'model.layers.30.mlp.up_proj.tlut', 'model.layers.17.mlp.down_proj.trellis', 'model.layers.30.self_attn.o_proj.tlut', 'model.layers.4.self_attn.v_proj.SV', 'model.layers.8.mlp.up_proj.tlut', 'model.layers.17.self_attn.v_proj.trellis', 'model.layers.16.mlp.up_proj.SV', 'model.layers.11.self_attn.q_proj.SV', 'model.layers.7.mlp.down_proj.trellis', 'model.layers.17.self_attn.q_proj.SU', 'model.layers.9.self_attn.o_proj.SV', 'model.layers.4.self_attn.o_proj.SV', 'model.layers.0.mlp.down_proj.tlut', 'model.layers.8.mlp.gate_proj.SV', 'model.layers.8.self_attn.o_proj.SV', 'model.layers.2.self_attn.q_proj.SV', 'model.layers.30.mlp.gate_proj.trellis', 'model.layers.9.self_attn.v_proj.trellis', 'model.layers.18.mlp.gate_proj.SV', 'model.layers.30.self_attn.q_proj.tlut', 'model.layers.26.self_attn.v_proj.trellis', 'model.layers.10.self_attn.v_proj.SU', 'model.layers.11.mlp.down_proj.trellis', 'model.layers.28.self_attn.o_proj.trellis', 'model.layers.1.mlp.up_proj.SV', 'model.layers.27.mlp.up_proj.tlut', 'model.layers.3.mlp.up_proj.SU', 'model.layers.9.self_attn.o_proj.tlut', 'model.layers.7.self_attn.k_proj.SU', 'model.layers.5.self_attn.v_proj.SV', 'model.layers.1.mlp.down_proj.SV', 'model.layers.11.mlp.gate_proj.SV', 'model.layers.2.self_attn.v_proj.SV', 'model.layers.27.mlp.gate_proj.SV', 'model.layers.31.self_attn.v_proj.trellis', 'model.layers.17.self_attn.o_proj.tlut', 'model.layers.30.mlp.up_proj.SU', 'model.layers.1.mlp.up_proj.SU', 'model.layers.31.mlp.gate_proj.tlut', 'model.layers.22.self_attn.v_proj.trellis', 'model.layers.12.mlp.up_proj.trellis', 'model.layers.25.mlp.down_proj.tlut', 'model.layers.4.mlp.up_proj.trellis', 'model.layers.9.mlp.down_proj.SU', 'model.layers.12.self_attn.o_proj.SV', 'model.layers.23.self_attn.k_proj.tlut', 'model.layers.12.mlp.down_proj.SU', 'model.layers.21.self_attn.q_proj.tlut', 'model.layers.31.mlp.gate_proj.SV', 'model.layers.29.self_attn.v_proj.SV', 'model.layers.11.self_attn.k_proj.SU', 'model.layers.22.mlp.down_proj.tlut', 'model.layers.29.mlp.gate_proj.SU', 'model.layers.22.self_attn.k_proj.tlut', 'model.layers.1.self_attn.k_proj.SU', 'model.layers.3.mlp.gate_proj.SU', 'model.layers.28.self_attn.k_proj.SU', 'model.layers.15.self_attn.o_proj.tlut', 'model.layers.21.self_attn.v_proj.trellis', 'model.layers.22.self_attn.o_proj.SV', 'model.layers.21.self_attn.o_proj.SU', 'model.layers.10.self_attn.k_proj.trellis', 'model.layers.11.mlp.up_proj.trellis', 'model.layers.13.self_attn.v_proj.SV', 'model.layers.21.self_attn.v_proj.SV', 'model.layers.3.mlp.down_proj.tlut', 'model.layers.31.mlp.up_proj.SU', 'model.layers.18.self_attn.o_proj.tlut', 'model.layers.25.mlp.gate_proj.SU', 'model.layers.21.self_attn.o_proj.tlut', 'model.layers.10.mlp.up_proj.SU', 'model.layers.1.self_attn.o_proj.tlut', 'model.layers.13.self_attn.q_proj.SU', 'model.layers.17.mlp.gate_proj.SU', 'model.layers.30.self_attn.k_proj.trellis', 'model.layers.27.mlp.down_proj.SU', 'model.layers.19.self_attn.q_proj.trellis', 'model.layers.25.mlp.gate_proj.tlut', 'model.layers.13.self_attn.k_proj.SU', 'model.layers.19.mlp.down_proj.SV', 'model.layers.22.self_attn.q_proj.tlut', 'model.layers.13.self_attn.q_proj.tlut', 'model.layers.21.self_attn.k_proj.SU', 'model.layers.22.self_attn.o_proj.SU', 'model.layers.21.self_attn.q_proj.trellis', 'model.layers.27.self_attn.k_proj.SU', 'model.layers.28.mlp.gate_proj.SV', 'model.layers.5.mlp.down_proj.SU', 'model.layers.26.mlp.gate_proj.trellis', 'model.layers.18.mlp.up_proj.tlut', 'model.layers.10.self_attn.q_proj.SV', 'model.layers.10.self_attn.v_proj.trellis', 'model.layers.5.self_attn.o_proj.SU', 'model.layers.1.self_attn.q_proj.tlut', 'model.layers.16.mlp.down_proj.trellis', 'model.layers.25.self_attn.o_proj.tlut', 'model.layers.26.self_attn.k_proj.SV', 'model.layers.16.mlp.gate_proj.SU', 'model.layers.4.mlp.up_proj.SV', 'model.layers.15.self_attn.k_proj.tlut', 'model.layers.16.self_attn.q_proj.SV', 'model.layers.6.mlp.up_proj.tlut', 'model.layers.2.self_attn.k_proj.trellis', 'model.layers.15.self_attn.v_proj.tlut', 'model.layers.15.self_attn.o_proj.trellis', 'model.layers.7.mlp.up_proj.trellis', 'model.layers.0.self_attn.k_proj.tlut', 'model.layers.1.self_attn.q_proj.trellis', 'model.layers.28.self_attn.v_proj.trellis', 'model.layers.3.self_attn.q_proj.SV', 'model.layers.24.mlp.gate_proj.SV', 'model.layers.24.self_attn.q_proj.SU', 'model.layers.20.mlp.up_proj.SU', 'model.layers.25.self_attn.v_proj.tlut', 'model.layers.29.self_attn.q_proj.SV', 'model.layers.5.mlp.up_proj.SV', 'model.layers.12.mlp.up_proj.SU', 'model.layers.5.self_attn.q_proj.tlut', 'model.layers.29.mlp.gate_proj.trellis', 'model.layers.10.mlp.up_proj.SV', 'model.layers.2.self_attn.v_proj.trellis', 'model.layers.5.mlp.down_proj.trellis', 'model.layers.21.self_attn.q_proj.SV', 'model.layers.24.self_attn.q_proj.trellis', 'model.layers.11.self_attn.k_proj.tlut', 'model.layers.9.self_attn.q_proj.trellis', 'model.layers.12.self_attn.k_proj.trellis', 'model.layers.2.self_attn.o_proj.tlut', 'model.layers.10.self_attn.v_proj.tlut', 'model.layers.12.self_attn.v_proj.tlut', 'model.layers.18.mlp.up_proj.trellis', 'model.layers.4.self_attn.q_proj.trellis', 'model.layers.8.mlp.down_proj.SV', 'model.layers.14.self_attn.o_proj.SU', 'model.layers.6.self_attn.o_proj.SU', 'model.layers.8.self_attn.q_proj.SV', 'model.layers.26.mlp.down_proj.SU', 'model.layers.2.mlp.gate_proj.trellis', 'model.layers.25.mlp.down_proj.trellis', 'model.layers.28.mlp.gate_proj.trellis', 'model.layers.16.self_attn.o_proj.SV', 'model.layers.26.self_attn.q_proj.SU', 'model.layers.10.self_attn.v_proj.SV', 'model.layers.18.self_attn.q_proj.SV', 'model.layers.2.self_attn.q_proj.SU', 'model.layers.7.mlp.gate_proj.SU', 'model.layers.23.self_attn.q_proj.tlut', 'model.layers.31.self_attn.k_proj.tlut', 'model.layers.31.self_attn.v_proj.SV', 'model.layers.6.self_attn.o_proj.SV', 'model.layers.7.mlp.up_proj.SV', 'model.layers.19.mlp.down_proj.trellis', 'model.layers.1.mlp.up_proj.trellis', 'model.layers.19.self_attn.o_proj.SV', 'model.layers.26.mlp.up_proj.tlut', 'model.layers.1.self_attn.k_proj.SV', 'model.layers.3.self_attn.k_proj.trellis', 'model.layers.7.self_attn.o_proj.SV', 'model.layers.11.mlp.up_proj.tlut', 'model.layers.15.self_attn.q_proj.SV', 'model.layers.7.mlp.down_proj.tlut', 'model.layers.19.mlp.gate_proj.trellis', 'model.layers.24.self_attn.o_proj.trellis', 'model.layers.22.self_attn.v_proj.tlut', 'model.layers.27.self_attn.v_proj.SV', 'model.layers.11.self_attn.v_proj.tlut', 'model.layers.14.self_attn.v_proj.SV', 'model.layers.24.mlp.down_proj.SU', 'model.layers.13.self_attn.o_proj.tlut', 'model.layers.19.self_attn.o_proj.trellis', 'model.layers.21.mlp.gate_proj.SV', 'model.layers.21.mlp.up_proj.SV', 'model.layers.11.mlp.down_proj.SV', 'model.layers.18.self_attn.k_proj.tlut', 'model.layers.20.self_attn.k_proj.trellis', 'model.layers.27.self_attn.v_proj.tlut', 'model.layers.21.mlp.gate_proj.SU', 'model.layers.15.self_attn.q_proj.SU', 'model.layers.0.mlp.down_proj.SV', 'model.layers.8.self_attn.k_proj.tlut', 'model.layers.27.self_attn.q_proj.tlut', 'model.layers.12.self_attn.k_proj.SU', 'model.layers.26.mlp.down_proj.trellis', 'model.layers.14.mlp.down_proj.trellis', 'model.layers.24.self_attn.k_proj.trellis', 'model.layers.27.mlp.gate_proj.tlut', 'model.layers.5.mlp.gate_proj.tlut', 'model.layers.17.mlp.down_proj.SV', 'model.layers.24.self_attn.k_proj.tlut', 'model.layers.26.self_attn.o_proj.tlut', 'model.layers.25.self_attn.v_proj.trellis', 'model.layers.5.self_attn.k_proj.tlut', 'model.layers.12.mlp.up_proj.SV', 'model.layers.13.mlp.down_proj.SU', 'model.layers.19.mlp.up_proj.SU', 'model.layers.26.self_attn.o_proj.SV', 'model.layers.18.self_attn.v_proj.SU', 'model.layers.18.mlp.down_proj.SU', 'model.layers.22.mlp.down_proj.SV', 'model.layers.3.mlp.gate_proj.tlut', 'model.layers.3.self_attn.q_proj.tlut', 'model.layers.4.mlp.gate_proj.SV', 'model.layers.0.mlp.up_proj.SV', 'model.layers.24.mlp.down_proj.trellis', 'model.layers.29.mlp.up_proj.trellis', 'model.layers.16.self_attn.k_proj.trellis', 'model.layers.14.self_attn.k_proj.SV', 'model.layers.17.self_attn.o_proj.trellis', 'model.layers.12.self_attn.q_proj.tlut', 'model.layers.11.self_attn.q_proj.tlut', 'model.layers.24.mlp.gate_proj.SU', 'model.layers.20.self_attn.k_proj.tlut', 'model.layers.17.mlp.down_proj.tlut', 'model.layers.10.self_attn.q_proj.trellis', 'model.layers.16.self_attn.q_proj.tlut', 'model.layers.3.mlp.up_proj.trellis', 'model.layers.21.mlp.down_proj.SU', 'model.layers.10.self_attn.q_proj.tlut', 'model.layers.5.mlp.gate_proj.SU', 'model.layers.4.self_attn.k_proj.SU', 'model.layers.15.self_attn.k_proj.SV', 'model.layers.2.self_attn.k_proj.tlut', 'model.layers.4.self_attn.v_proj.tlut', 'model.layers.9.self_attn.q_proj.tlut', 'model.layers.0.self_attn.k_proj.SU', 'model.layers.18.self_attn.v_proj.tlut', 'model.layers.12.self_attn.k_proj.SV', 'model.layers.18.self_attn.o_proj.trellis', 'model.layers.25.self_attn.k_proj.SU', 'model.layers.30.mlp.gate_proj.tlut', 'model.layers.25.self_attn.q_proj.tlut', 'model.layers.8.mlp.gate_proj.trellis', 'model.layers.2.mlp.down_proj.tlut', 'model.layers.22.mlp.gate_proj.SU', 'model.layers.18.self_attn.q_proj.SU', 'model.layers.28.self_attn.v_proj.SU', 'model.layers.30.self_attn.q_proj.trellis', 'model.layers.15.mlp.down_proj.tlut', 'model.layers.4.self_attn.o_proj.tlut', 'model.layers.28.mlp.down_proj.tlut', 'model.layers.9.mlp.gate_proj.SV', 'model.layers.17.mlp.down_proj.SU', 'model.layers.30.self_attn.k_proj.SU', 'model.layers.17.mlp.up_proj.tlut', 'model.layers.23.self_attn.v_proj.trellis', 'model.layers.20.self_attn.k_proj.SV', 'model.layers.29.self_attn.o_proj.SU', 'model.layers.31.self_attn.q_proj.SV', 'model.layers.4.mlp.up_proj.SU', 'model.layers.9.mlp.up_proj.trellis', 'model.layers.1.self_attn.v_proj.trellis', 'model.layers.18.mlp.down_proj.tlut', 'model.layers.23.mlp.up_proj.SU', 'model.layers.25.self_attn.q_proj.trellis', 'model.layers.5.mlp.up_proj.tlut', 'model.layers.10.self_attn.o_proj.tlut', 'model.layers.1.mlp.gate_proj.SV', 'model.layers.1.self_attn.o_proj.SU', 'model.layers.19.self_attn.q_proj.SU', 'model.layers.17.self_attn.v_proj.SV', 'model.layers.22.self_attn.k_proj.trellis', 'model.layers.28.mlp.up_proj.SV', 'model.layers.25.self_attn.k_proj.trellis', 'model.layers.31.self_attn.v_proj.SU', 'model.layers.20.self_attn.v_proj.tlut', 'model.layers.22.self_attn.k_proj.SV', 'model.layers.24.self_attn.v_proj.SV', 'model.layers.3.self_attn.o_proj.tlut', 'model.layers.29.mlp.up_proj.SV', 'model.layers.20.mlp.gate_proj.tlut', 'model.layers.16.self_attn.k_proj.tlut', 'model.layers.7.mlp.down_proj.SU', 'model.layers.7.self_attn.q_proj.trellis', 'model.layers.11.mlp.down_proj.tlut', 'model.layers.9.self_attn.k_proj.trellis', 'model.layers.0.self_attn.v_proj.SU', 'model.layers.10.mlp.gate_proj.tlut', 'model.layers.17.mlp.up_proj.SV', 'model.layers.17.mlp.up_proj.SU', 'model.layers.14.mlp.down_proj.SU', 'model.layers.17.mlp.gate_proj.trellis', 'model.layers.23.mlp.down_proj.SV', 'model.layers.19.mlp.up_proj.trellis', 'model.layers.6.self_attn.q_proj.tlut', 'model.layers.12.self_attn.q_proj.SV', 'model.layers.12.self_attn.v_proj.SV', 'model.layers.7.self_attn.o_proj.tlut', 'model.layers.20.self_attn.q_proj.SU', 'model.layers.29.mlp.down_proj.trellis', 'model.layers.26.self_attn.q_proj.SV', 'model.layers.17.self_attn.o_proj.SV', 'model.layers.22.self_attn.o_proj.tlut', 'model.layers.6.mlp.gate_proj.trellis', 'model.layers.2.mlp.up_proj.trellis', 'model.layers.1.mlp.gate_proj.SU', 'model.layers.29.mlp.gate_proj.tlut', 'model.layers.23.mlp.gate_proj.SU', 'model.layers.17.self_attn.k_proj.trellis', 'model.layers.14.self_attn.q_proj.SV', 'model.layers.9.self_attn.o_proj.SU', 'model.layers.20.self_attn.o_proj.SV', 'model.layers.14.mlp.up_proj.SV', 'model.layers.30.self_attn.v_proj.trellis', 'model.layers.29.self_attn.o_proj.tlut', 'model.layers.4.mlp.gate_proj.trellis', 'model.layers.23.self_attn.o_proj.SU', 'model.layers.1.self_attn.k_proj.tlut', 'model.layers.13.mlp.down_proj.SV', 'model.layers.22.self_attn.o_proj.trellis', 'model.layers.30.self_attn.v_proj.tlut', 'model.layers.31.self_attn.q_proj.tlut', 'model.layers.22.self_attn.v_proj.SV', 'model.layers.0.mlp.down_proj.SU', 'model.layers.5.self_attn.v_proj.SU', 'model.layers.22.mlp.up_proj.trellis', 'model.layers.20.self_attn.q_proj.trellis', 'model.layers.2.self_attn.k_proj.SV', 'model.layers.30.mlp.up_proj.SV', 'model.layers.5.mlp.up_proj.trellis', 'model.layers.30.mlp.gate_proj.SV', 'model.layers.1.mlp.down_proj.trellis', 'model.layers.5.mlp.gate_proj.SV', 'model.layers.24.self_attn.v_proj.trellis', 'model.layers.9.mlp.gate_proj.trellis', 'model.layers.14.self_attn.q_proj.SU', 'model.layers.9.self_attn.k_proj.SV', 'model.layers.27.self_attn.k_proj.trellis', 'model.layers.27.self_attn.o_proj.SU', 'model.layers.19.self_attn.q_proj.tlut', 'model.layers.15.self_attn.v_proj.SU', 'model.layers.15.self_attn.v_proj.trellis', 'model.layers.9.self_attn.v_proj.tlut', 'model.layers.17.self_attn.q_proj.SV', 'model.layers.18.self_attn.k_proj.SV', 'model.layers.25.self_attn.o_proj.trellis', 'model.layers.25.self_attn.q_proj.SV', 'model.layers.15.mlp.up_proj.SU', 'model.layers.6.self_attn.k_proj.SV', 'model.layers.23.mlp.up_proj.SV', 'model.layers.6.self_attn.k_proj.trellis', 'model.layers.18.self_attn.v_proj.trellis', 'model.layers.26.mlp.gate_proj.SV', 'model.layers.0.mlp.down_proj.trellis', 'model.layers.6.self_attn.k_proj.tlut', 'model.layers.4.mlp.down_proj.SV', 'model.layers.13.self_attn.q_proj.trellis', 'model.layers.15.mlp.down_proj.SU', 'model.layers.7.mlp.gate_proj.tlut', 'model.layers.20.self_attn.o_proj.tlut', 'model.layers.8.mlp.up_proj.trellis', 'model.layers.4.self_attn.q_proj.tlut', 'model.layers.2.self_attn.q_proj.trellis', 'model.layers.11.self_attn.v_proj.trellis', 'model.layers.13.mlp.down_proj.tlut', 'model.layers.18.mlp.gate_proj.trellis', 'model.layers.12.self_attn.o_proj.trellis', 'model.layers.29.self_attn.o_proj.SV', 'model.layers.8.self_attn.q_proj.tlut', 'model.layers.20.mlp.gate_proj.SV', 'model.layers.19.mlp.down_proj.tlut', 'model.layers.13.mlp.down_proj.trellis', 'model.layers.16.self_attn.k_proj.SV', 'model.layers.28.self_attn.k_proj.trellis', 'model.layers.14.self_attn.k_proj.trellis', 'model.layers.23.self_attn.v_proj.tlut', 'model.layers.31.mlp.gate_proj.SU', 'model.layers.20.mlp.up_proj.SV', 'model.layers.13.self_attn.o_proj.SV', 'model.layers.13.self_attn.v_proj.SU', 'model.layers.16.mlp.down_proj.SV', 'model.layers.25.mlp.down_proj.SU', 'model.layers.15.self_attn.o_proj.SU', 'model.layers.6.self_attn.v_proj.SV', 'model.layers.23.self_attn.v_proj.SU', 'model.layers.16.self_attn.v_proj.trellis', 'model.layers.2.self_attn.k_proj.SU', 'model.layers.23.mlp.down_proj.trellis', 'model.layers.29.mlp.up_proj.SU', 'model.layers.11.self_attn.q_proj.trellis', 'model.layers.8.mlp.up_proj.SU', 'model.layers.15.self_attn.q_proj.trellis', 'model.layers.23.self_attn.v_proj.SV', 'model.layers.16.mlp.down_proj.SU', 'model.layers.24.self_attn.q_proj.tlut', 'model.layers.15.mlp.down_proj.SV', 'model.layers.20.self_attn.o_proj.SU', 'model.layers.12.mlp.down_proj.tlut', 'model.layers.8.mlp.down_proj.trellis', 'model.layers.6.mlp.down_proj.SU', 'model.layers.30.mlp.up_proj.trellis', 'model.layers.8.mlp.down_proj.tlut', 'model.layers.23.mlp.gate_proj.trellis', 'model.layers.7.self_attn.q_proj.tlut', 'model.layers.26.mlp.up_proj.SU', 'model.layers.0.self_attn.q_proj.SU', 'model.layers.8.self_attn.o_proj.tlut', 'model.layers.7.self_attn.k_proj.SV', 'model.layers.16.mlp.gate_proj.trellis', 'model.layers.28.mlp.up_proj.trellis', 'model.layers.16.mlp.gate_proj.SV', 'model.layers.14.mlp.up_proj.SU', 'model.layers.18.mlp.up_proj.SV', 'model.layers.2.mlp.up_proj.SU', 'model.layers.8.mlp.gate_proj.tlut', 'model.layers.27.self_attn.q_proj.SV', 'model.layers.12.self_attn.k_proj.tlut', 'model.layers.25.mlp.gate_proj.SV', 'model.layers.31.mlp.up_proj.SV', 'model.layers.3.self_attn.v_proj.SV', 'model.layers.27.self_attn.q_proj.SU', 'model.layers.5.self_attn.q_proj.SU', 'model.layers.27.mlp.up_proj.trellis', 'model.layers.17.self_attn.q_proj.trellis', 'model.layers.19.self_attn.k_proj.SU', 'model.layers.25.self_attn.o_proj.SV', 'model.layers.6.self_attn.o_proj.tlut', 'model.layers.22.self_attn.v_proj.SU', 'model.layers.0.self_attn.k_proj.trellis', 'model.layers.26.self_attn.q_proj.tlut', 'model.layers.30.mlp.down_proj.SU', 'model.layers.5.self_attn.v_proj.tlut', 'model.layers.23.mlp.up_proj.tlut', 'model.layers.12.mlp.gate_proj.SV', 'model.layers.4.self_attn.v_proj.trellis', 'model.layers.12.mlp.gate_proj.trellis', 'model.layers.7.self_attn.o_proj.trellis', 'model.layers.0.mlp.up_proj.SU', 'model.layers.1.mlp.down_proj.tlut', 'model.layers.28.mlp.gate_proj.SU', 'model.layers.24.self_attn.o_proj.tlut', 'model.layers.24.mlp.up_proj.trellis', 'model.layers.20.mlp.down_proj.SV', 'model.layers.30.self_attn.q_proj.SV', 'model.layers.13.self_attn.o_proj.trellis', 'model.layers.5.self_attn.v_proj.trellis', 'model.layers.15.self_attn.k_proj.trellis', 'model.layers.1.self_attn.q_proj.SV', 'model.layers.21.self_attn.q_proj.SU', 'model.layers.4.mlp.down_proj.trellis', 'model.layers.16.self_attn.v_proj.tlut', 'model.layers.18.self_attn.k_proj.SU', 'model.layers.27.self_attn.v_proj.trellis', 'model.layers.28.self_attn.k_proj.SV', 'model.layers.28.self_attn.o_proj.SV', 'model.layers.13.self_attn.v_proj.tlut', 'model.layers.1.self_attn.o_proj.trellis', 'model.layers.25.self_attn.k_proj.SV', 'model.layers.12.self_attn.o_proj.tlut', 'model.layers.16.self_attn.o_proj.tlut', 'model.layers.12.self_attn.v_proj.trellis', 'model.layers.12.mlp.gate_proj.SU', 'model.layers.13.self_attn.k_proj.trellis', 'model.layers.22.mlp.gate_proj.trellis', 'model.layers.3.self_attn.q_proj.SU', 'model.layers.4.self_attn.o_proj.SU', 'model.layers.18.mlp.up_proj.SU', 'model.layers.3.mlp.down_proj.trellis', 'model.layers.2.self_attn.o_proj.trellis', 'model.layers.29.self_attn.q_proj.SU', 'model.layers.25.mlp.down_proj.SV', 'model.layers.0.mlp.gate_proj.SU', 'model.layers.21.self_attn.k_proj.tlut', 'model.layers.0.self_attn.q_proj.tlut', 'model.layers.28.mlp.down_proj.trellis', 'model.layers.24.self_attn.v_proj.tlut', 'model.layers.11.self_attn.o_proj.tlut', 'model.layers.17.self_attn.k_proj.SU', 'model.layers.22.mlp.down_proj.SU', 'model.layers.13.self_attn.q_proj.SV', 'model.layers.31.mlp.down_proj.SU', 'model.layers.7.self_attn.o_proj.SU', 'model.layers.29.self_attn.k_proj.trellis', 'model.layers.16.mlp.up_proj.tlut', 'model.layers.10.self_attn.k_proj.SV', 'model.layers.5.mlp.down_proj.tlut', 'model.layers.2.self_attn.v_proj.tlut', 'model.layers.7.mlp.up_proj.SU', 'model.layers.30.self_attn.q_proj.SU', 'model.layers.10.self_attn.o_proj.SV', 'model.layers.28.self_attn.q_proj.SV', 'model.layers.29.mlp.up_proj.tlut', 'model.layers.7.self_attn.k_proj.tlut', 'model.layers.30.mlp.down_proj.trellis', 'model.layers.15.self_attn.v_proj.SV', 'model.layers.31.mlp.down_proj.SV', 'model.layers.14.self_attn.o_proj.SV', 'model.layers.13.mlp.up_proj.trellis', 'model.layers.30.mlp.down_proj.SV', 'model.layers.8.self_attn.v_proj.trellis', 'model.layers.13.self_attn.v_proj.trellis', 'model.layers.18.mlp.gate_proj.tlut', 'model.layers.12.mlp.down_proj.trellis', 'model.layers.4.self_attn.o_proj.trellis', 'model.layers.10.self_attn.k_proj.SU', 'model.layers.17.self_attn.k_proj.SV', 'model.layers.23.mlp.down_proj.SU', 'model.layers.1.self_attn.o_proj.SV', 'model.layers.4.mlp.gate_proj.SU', 'model.layers.29.self_attn.q_proj.trellis', 'model.layers.24.self_attn.o_proj.SV', 'model.layers.28.self_attn.q_proj.tlut', 'model.layers.2.mlp.gate_proj.tlut', 'model.layers.19.mlp.gate_proj.SV', 'model.layers.1.mlp.gate_proj.trellis', 'model.layers.18.mlp.gate_proj.SU', 'model.layers.6.self_attn.q_proj.SV', 'model.layers.9.self_attn.v_proj.SU', 'model.layers.2.self_attn.o_proj.SU', 'model.layers.14.self_attn.v_proj.SU', 'model.layers.23.self_attn.q_proj.SU', 'model.layers.31.self_attn.o_proj.trellis', 'model.layers.9.self_attn.k_proj.SU', 'model.layers.20.self_attn.v_proj.SU', 'model.layers.21.self_attn.v_proj.SU', 'model.layers.7.mlp.gate_proj.SV', 'model.layers.19.mlp.gate_proj.SU', 'model.layers.19.self_attn.v_proj.SU', 'model.layers.1.self_attn.k_proj.trellis', 'model.layers.18.self_attn.k_proj.trellis', 'model.layers.17.self_attn.k_proj.tlut', 'model.layers.19.mlp.down_proj.SU', 'model.layers.4.mlp.up_proj.tlut', 'model.layers.10.mlp.gate_proj.trellis', 'model.layers.22.mlp.down_proj.trellis', 'model.layers.24.self_attn.k_proj.SU', 'model.layers.9.self_attn.q_proj.SV', 'model.layers.9.mlp.up_proj.SV', 'model.layers.9.mlp.down_proj.tlut', 'model.layers.16.self_attn.o_proj.SU', 'model.layers.10.self_attn.o_proj.trellis', 'model.layers.5.self_attn.q_proj.SV', 'model.layers.21.self_attn.v_proj.tlut', 'model.layers.1.self_attn.v_proj.SU', 'model.layers.10.self_attn.k_proj.tlut', 'model.layers.1.self_attn.v_proj.SV', 'model.layers.28.self_attn.v_proj.tlut', 'model.layers.27.mlp.gate_proj.SU', 'model.layers.30.mlp.down_proj.tlut', 'model.layers.17.mlp.gate_proj.SV', 'model.layers.30.self_attn.o_proj.SU', 'model.layers.8.self_attn.o_proj.SU', 'model.layers.28.mlp.up_proj.SU', 'model.layers.13.self_attn.k_proj.tlut', 'model.layers.7.self_attn.v_proj.SV', 'model.layers.8.self_attn.q_proj.trellis', 'model.layers.9.self_attn.o_proj.trellis', 'model.layers.22.self_attn.k_proj.SU', 'model.layers.14.mlp.gate_proj.tlut', 'model.layers.16.self_attn.k_proj.SU', 'model.layers.23.mlp.down_proj.tlut', 'model.layers.19.mlp.gate_proj.tlut', 'model.layers.23.self_attn.q_proj.trellis', 'model.layers.1.self_attn.v_proj.tlut', 'model.layers.5.mlp.down_proj.SV', 'model.layers.27.mlp.down_proj.trellis', 'model.layers.23.self_attn.k_proj.SV', 'model.layers.12.self_attn.q_proj.trellis', 'model.layers.17.mlp.gate_proj.tlut', 'model.layers.0.self_attn.q_proj.SV', 'model.layers.14.self_attn.q_proj.tlut', 'model.layers.13.mlp.up_proj.SV', 'model.layers.27.self_attn.k_proj.tlut', 'model.layers.20.self_attn.q_proj.SV', 'model.layers.6.self_attn.v_proj.trellis', 'model.layers.4.self_attn.q_proj.SV', 'model.layers.26.mlp.up_proj.SV', 'model.layers.23.self_attn.o_proj.tlut', 'model.layers.0.self_attn.v_proj.SV', 'model.layers.16.self_attn.q_proj.trellis', 'model.layers.19.self_attn.k_proj.SV', 'model.layers.24.mlp.up_proj.tlut', 'model.layers.26.self_attn.q_proj.trellis', 'model.layers.26.mlp.gate_proj.SU', 'model.layers.19.self_attn.k_proj.trellis', 'model.layers.2.mlp.up_proj.tlut', 'model.layers.10.mlp.down_proj.trellis', 'model.layers.29.self_attn.q_proj.tlut', 'model.layers.1.self_attn.q_proj.SU', 'model.layers.14.mlp.gate_proj.SU', 'model.layers.20.mlp.down_proj.tlut', 'model.layers.3.self_attn.k_proj.SU', 'model.layers.23.mlp.gate_proj.tlut', 'model.layers.12.mlp.down_proj.SV', 'model.layers.25.self_attn.v_proj.SV', 'model.layers.21.self_attn.k_proj.trellis', 'model.layers.13.mlp.up_proj.SU', 'model.layers.3.self_attn.v_proj.tlut', 'model.layers.28.mlp.down_proj.SV', 'model.layers.0.mlp.up_proj.trellis', 'model.layers.6.mlp.gate_proj.SV', 'model.layers.15.mlp.down_proj.trellis', 'model.layers.14.self_attn.v_proj.trellis', 'model.layers.12.mlp.gate_proj.tlut', 'model.layers.25.mlp.up_proj.trellis', 'model.layers.12.self_attn.q_proj.SU', 'model.layers.21.mlp.gate_proj.tlut', 'model.layers.26.self_attn.k_proj.SU', 'model.layers.10.mlp.gate_proj.SV', 'model.layers.11.self_attn.k_proj.SV', 'model.layers.21.mlp.down_proj.trellis', 'model.layers.2.mlp.down_proj.SV', 'model.layers.0.mlp.gate_proj.SV', 'model.layers.31.self_attn.q_proj.trellis', 'model.layers.19.self_attn.k_proj.tlut', 'model.layers.28.mlp.down_proj.SU', 'model.layers.10.mlp.down_proj.SV', 'model.layers.29.mlp.down_proj.tlut', 'model.layers.26.self_attn.k_proj.tlut', 'model.layers.24.self_attn.q_proj.SV', 'model.layers.29.self_attn.v_proj.SU', 'model.layers.6.self_attn.v_proj.SU', 'model.layers.23.self_attn.o_proj.SV', 'model.layers.20.self_attn.k_proj.SU', 'model.layers.19.mlp.up_proj.SV', 'model.layers.12.self_attn.v_proj.SU', 'model.layers.21.mlp.down_proj.tlut', 'model.layers.16.self_attn.o_proj.trellis', 'model.layers.22.mlp.up_proj.SU', 'model.layers.28.self_attn.q_proj.trellis', 'model.layers.8.self_attn.q_proj.SU', 'model.layers.9.mlp.up_proj.tlut', 'model.layers.28.self_attn.q_proj.SU', 'model.layers.21.self_attn.k_proj.SV', 'model.layers.17.self_attn.v_proj.SU', 'model.layers.10.self_attn.o_proj.SU', 'model.layers.3.mlp.gate_proj.trellis', 'model.layers.6.mlp.down_proj.tlut', 'model.layers.27.self_attn.o_proj.tlut', 'model.layers.17.self_attn.v_proj.tlut', 'model.layers.29.mlp.gate_proj.SV', 'model.layers.20.self_attn.v_proj.SV', 'model.layers.6.mlp.up_proj.SV', 'model.layers.16.mlp.up_proj.trellis', 'model.layers.3.self_attn.q_proj.trellis', 'model.layers.24.mlp.down_proj.SV'}\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at relaxml/Llama-3.1-8B-Instruct-QTIP-2Bit and are newly initialized: ['model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2d958aa977a9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Generate a Python function that calculates the area of a rectangle given its length and width.\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m ]\n\u001b[0;32m---> 27\u001b[0;31m outputs = pipeline(\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Increased token count to get a complete response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                     \u001b[0mchats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mChat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 🐈 🐈 🐈\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m             )\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation_config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2256\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3255\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3257\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    593\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_id = \"relaxml/Llama-3.1-8B-Instruct-QTIP-2Bit\"\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# تعيين قالب المحادثة للنموذج\n",
        "tokenizer = pipeline.tokenizer\n",
        "tokenizer.chat_template = \"{% for message in messages %}\\n{% if message['role'] == 'system' %}\\n<|system|>\\n{{ message['content'] }}\\n{% elif message['role'] == 'user' %}\\n<|user|>\\n{{ message['content'] }}\\n{% elif message['role'] == 'assistant' %}\\n<|assistant|>\\n{{ message['content'] }}\\n{% endif %}\\n{% endfor %}\\n{% if add_generation_prompt %}\\n<|assistant|>\\n{% endif %}\"\n",
        "\n",
        "# إنشاء قائمة من الأسئلة المختلفة لاختبار النموذج\n",
        "test_questions = [\n",
        "    \"اكتب دالة بايثون لحساب مساحة المستطيل.\",\n",
        "    \"اشرح لي كيف يعمل خوارزمية البحث الثنائي بالتفصيل.\",\n",
        "    \"قم بإنشاء مثال لاستخدام pandas لتحليل بيانات في ملف CSV.\",\n",
        "    \"اكتب برنامج بسيط يقوم بإنشاء محفظة للعملات المشفرة.\"\n",
        "]\n",
        "\n",
        "# وظيفة لاختبار سؤال واحد وطباعة النتيجة\n",
        "def test_model_response(question):\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(f\"السؤال: {question}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # تهيئة الرسائل للنموذج\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"أنت مساعد مفيد يجيب دائمًا بطريقة واضحة ومفصلة وبكود قابل للتنفيذ.\"},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ]\n",
        "\n",
        "    # توليد الإجابة\n",
        "    outputs = pipeline(\n",
        "        messages,\n",
        "        max_new_tokens=512,  # زيادة عدد الكلمات المولدة للحصول على إجابات أكثر اكتمالاً\n",
        "        do_sample=True,\n",
        "        temperature=0.7,  # إضافة درجة حرارة معتدلة لتنويع الإجابات\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    # استخراج وطباعة الإجابة\n",
        "    if isinstance(outputs[0][\"generated_text\"], list):\n",
        "        response = outputs[0][\"generated_text\"][-1][\"content\"]\n",
        "    else:\n",
        "        generated_text = outputs[0][\"generated_text\"]\n",
        "        response = generated_text.split(\"<|assistant|>\")[-1].strip()\n",
        "\n",
        "    print(\"\\nإجابة النموذج:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(response)\n",
        "    print(\"-\" * 50)\n",
        "    return response\n",
        "\n",
        "# اختبار النموذج مع جميع الأسئلة\n",
        "for question in test_questions:\n",
        "    test_model_response(question)\n",
        "\n",
        "# اختبار باستخدام سؤال باللغة الإنجليزية أيضًا\n",
        "english_question = \"Explain how transformers work in deep learning and give a simple implementation example.\"\n",
        "test_model_response(english_question)"
      ],
      "metadata": {
        "id": "xkS6kJri7tIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_questions = [\n",
        "\"Write a Python function to calculate the area of ​​a rectangle.\",\n",
        "\"Explain to me in detail how the binary search algorithm works.\",\n",
        "\"Create an example of using pandas to parse data in a CSV file.\",\n",
        "\"Write a simple program that creates a cryptocurrency wallet.\"\n",
        "]"
      ],
      "metadata": {
        "id": "hEJOBwaP7yk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_id = \"relaxml/Llama-3.1-8B-Instruct-QTIP-2Bit\"\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# تعيين قالب المحادثة للنموذج\n",
        "tokenizer = pipeline.tokenizer\n",
        "tokenizer.chat_template = \"{% for message in messages %}\\n{% if message['role'] == 'system' %}\\n<|system|>\\n{{ message['content'] }}\\n{% elif message['role'] == 'user' %}\\n<|user|>\\n{{ message['content'] }}\\n{% elif message['role'] == 'assistant' %}\\n<|assistant|>\\n{{ message['content'] }}\\n{% endif %}\\n{% endfor %}\\n{% if add_generation_prompt %}\\n<|assistant|>\\n{% endif %}\"\n",
        "\n",
        "# إنشاء قائمة من الأسئلة المختلفة لاختبار النموذج\n",
        "test_questions = [\n",
        "\"Write a Python function to calculate the area of ​​a rectangle.\",\n",
        "\"Explain to me in detail how the binary search algorithm works.\",\n",
        "\"Create an example of using pandas to parse data in a CSV file.\",\n",
        "\"Write a simple program that creates a cryptocurrency wallet.\"\n",
        "]\n",
        "\n",
        "# وظيفة لاختبار سؤال واحد وطباعة النتيجة\n",
        "def test_model_response(question):\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(f\"السؤال: {question}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # تهيئة الرسائل للنموذج\n",
        "    messages = [\n",
        "{\"role\": \"system\", \"content\": \"You are a helpful assistant who always answers clearly, in detail, and with executable code.\"},\n",
        "{\"role\": \"user\", \"content\": question},\n",
        "                 ]\n",
        "\n",
        "    # توليد الإجابة\n",
        "    outputs = pipeline(\n",
        "        messages,\n",
        "        max_new_tokens=22,  # زيادة عدد الكلمات المولدة للحصول على إجابات أكثر اكتمالاً\n",
        "        do_sample=True,\n",
        "        temperature=0.7,  # إضافة درجة حرارة معتدلة لتنويع الإجابات\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    # استخراج وطباعة الإجابة\n",
        "    if isinstance(outputs[0][\"generated_text\"], list):\n",
        "        response = outputs[0][\"generated_text\"][-1][\"content\"]\n",
        "    else:\n",
        "        generated_text = outputs[0][\"generated_text\"]\n",
        "        response = generated_text.split(\"<|assistant|>\")[-1].strip()\n",
        "\n",
        "    print(\"\\nإجابة النموذج:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(response)\n",
        "    print(\"-\" * 50)\n",
        "    return response\n",
        "\n",
        "# اختبار النموذج مع جميع الأسئلة\n",
        "for question in test_questions:\n",
        "    test_model_response(question)\n",
        "\n",
        "# اختبار باستخدام سؤال باللغة الإنجليزية أيضًا\n",
        "english_question = \"Explain how transformers work in deep learning and give a simple implementation example.\"\n",
        "test_model_response(english_question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "id": "55Wnwdib70GR",
        "outputId": "86850948-020f-4d9a-c8b1-2cb12858a445"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at relaxml/Llama-3.1-8B-Instruct-QTIP-2Bit were not used when initializing LlamaForCausalLM: {'model.layers.27.self_attn.o_proj.SV', 'model.layers.20.self_attn.k_proj.trellis', 'model.layers.26.self_attn.v_proj.SU', 'model.layers.12.self_attn.v_proj.tlut', 'model.layers.9.mlp.down_proj.trellis', 'model.layers.15.self_attn.k_proj.SU', 'model.layers.6.mlp.gate_proj.tlut', 'model.layers.11.self_attn.q_proj.SU', 'model.layers.9.self_attn.k_proj.tlut', 'model.layers.10.mlp.up_proj.SV', 'model.layers.26.mlp.gate_proj.SV', 'model.layers.11.mlp.gate_proj.SV', 'model.layers.10.mlp.down_proj.SV', 'model.layers.14.self_attn.q_proj.SV', 'model.layers.23.self_attn.q_proj.SU', 'model.layers.30.self_attn.v_proj.SV', 'model.layers.28.mlp.gate_proj.trellis', 'model.layers.5.self_attn.k_proj.tlut', 'model.layers.11.self_attn.k_proj.SV', 'model.layers.1.self_attn.q_proj.SV', 'model.layers.15.mlp.gate_proj.SU', 'model.layers.20.self_attn.o_proj.tlut', 'model.layers.15.self_attn.o_proj.trellis', 'model.layers.26.self_attn.v_proj.SV', 'model.layers.1.self_attn.v_proj.SU', 'model.layers.13.self_attn.k_proj.SU', 'model.layers.24.self_attn.o_proj.SV', 'model.layers.9.mlp.gate_proj.trellis', 'model.layers.19.mlp.up_proj.tlut', 'model.layers.16.self_attn.q_proj.SU', 'model.layers.19.mlp.up_proj.SV', 'model.layers.26.mlp.up_proj.tlut', 'model.layers.4.mlp.gate_proj.trellis', 'model.layers.30.mlp.down_proj.trellis', 'model.layers.7.self_attn.q_proj.trellis', 'model.layers.16.self_attn.v_proj.tlut', 'model.layers.24.self_attn.k_proj.SU', 'model.layers.8.self_attn.o_proj.SV', 'model.layers.2.self_attn.o_proj.SV', 'model.layers.24.self_attn.k_proj.SV', 'model.layers.17.mlp.down_proj.trellis', 'model.layers.3.self_attn.v_proj.trellis', 'model.layers.1.self_attn.o_proj.SV', 'model.layers.12.self_attn.o_proj.tlut', 'model.layers.20.self_attn.v_proj.SV', 'model.layers.23.self_attn.q_proj.trellis', 'model.layers.1.self_attn.k_proj.SU', 'model.layers.25.self_attn.o_proj.SV', 'model.layers.3.self_attn.o_proj.SV', 'model.layers.18.mlp.down_proj.tlut', 'model.layers.20.mlp.down_proj.trellis', 'model.layers.7.self_attn.k_proj.trellis', 'model.layers.7.mlp.down_proj.SV', 'model.layers.21.self_attn.v_proj.trellis', 'model.layers.10.mlp.gate_proj.SV', 'model.layers.11.self_attn.q_proj.tlut', 'model.layers.25.self_attn.k_proj.SU', 'model.layers.13.self_attn.k_proj.tlut', 'model.layers.16.mlp.up_proj.SV', 'model.layers.2.self_attn.v_proj.tlut', 'model.layers.10.self_attn.k_proj.trellis', 'model.layers.22.self_attn.o_proj.tlut', 'model.layers.1.mlp.gate_proj.SV', 'model.layers.22.self_attn.v_proj.tlut', 'model.layers.29.self_attn.q_proj.trellis', 'model.layers.21.mlp.down_proj.SV', 'model.layers.1.self_attn.q_proj.trellis', 'model.layers.17.self_attn.o_proj.SU', 'model.layers.11.self_attn.q_proj.trellis', 'model.layers.25.self_attn.v_proj.SU', 'model.layers.6.mlp.up_proj.trellis', 'model.layers.25.self_attn.q_proj.tlut', 'model.layers.29.self_attn.o_proj.trellis', 'model.layers.13.mlp.gate_proj.tlut', 'model.layers.2.self_attn.v_proj.trellis', 'model.layers.23.mlp.up_proj.SU', 'model.layers.0.self_attn.o_proj.tlut', 'model.layers.12.self_attn.q_proj.SV', 'model.layers.13.mlp.gate_proj.trellis', 'model.layers.7.mlp.up_proj.trellis', 'model.layers.30.mlp.up_proj.tlut', 'model.layers.27.mlp.gate_proj.SV', 'model.layers.16.mlp.gate_proj.SV', 'model.layers.4.self_attn.v_proj.SV', 'model.layers.15.self_attn.v_proj.SV', 'model.layers.24.self_attn.k_proj.tlut', 'model.layers.6.self_attn.q_proj.SU', 'model.layers.3.self_attn.k_proj.tlut', 'model.layers.31.mlp.down_proj.trellis', 'model.layers.22.mlp.down_proj.trellis', 'model.layers.27.mlp.gate_proj.SU', 'model.layers.25.mlp.up_proj.trellis', 'model.layers.25.mlp.down_proj.SV', 'model.layers.0.self_attn.v_proj.SV', 'model.layers.13.mlp.up_proj.trellis', 'model.layers.27.self_attn.q_proj.trellis', 'model.layers.2.mlp.gate_proj.tlut', 'model.layers.3.mlp.down_proj.SV', 'model.layers.22.mlp.gate_proj.SV', 'model.layers.1.self_attn.o_proj.SU', 'model.layers.23.self_attn.q_proj.tlut', 'model.layers.2.self_attn.v_proj.SU', 'model.layers.28.self_attn.v_proj.SV', 'model.layers.3.self_attn.v_proj.SV', 'model.layers.20.self_attn.k_proj.tlut', 'model.layers.29.mlp.gate_proj.tlut', 'model.layers.9.self_attn.q_proj.tlut', 'model.layers.30.self_attn.o_proj.tlut', 'model.layers.11.self_attn.v_proj.tlut', 'model.layers.25.self_attn.o_proj.trellis', 'model.layers.11.self_attn.o_proj.SU', 'model.layers.11.self_attn.o_proj.SV', 'model.layers.18.self_attn.k_proj.tlut', 'model.layers.26.mlp.down_proj.SV', 'model.layers.22.self_attn.q_proj.trellis', 'model.layers.29.mlp.up_proj.tlut', 'model.layers.4.self_attn.k_proj.SV', 'model.layers.28.mlp.up_proj.SV', 'model.layers.6.mlp.gate_proj.SU', 'model.layers.0.mlp.down_proj.SV', 'model.layers.4.self_attn.o_proj.SU', 'model.layers.0.self_attn.o_proj.SU', 'model.layers.18.mlp.gate_proj.trellis', 'model.layers.27.self_attn.k_proj.SU', 'model.layers.6.self_attn.k_proj.tlut', 'model.layers.25.self_attn.o_proj.SU', 'model.layers.14.self_attn.k_proj.SU', 'model.layers.27.self_attn.q_proj.SU', 'model.layers.0.self_attn.k_proj.SU', 'model.layers.26.mlp.down_proj.tlut', 'model.layers.2.self_attn.k_proj.SV', 'model.layers.4.mlp.up_proj.trellis', 'model.layers.15.self_attn.k_proj.SV', 'model.layers.13.mlp.down_proj.SU', 'model.layers.25.mlp.down_proj.SU', 'model.layers.24.self_attn.v_proj.SU', 'model.layers.28.mlp.gate_proj.SV', 'model.layers.10.self_attn.o_proj.SV', 'model.layers.27.mlp.up_proj.trellis', 'model.layers.29.mlp.down_proj.SV', 'model.layers.7.self_attn.v_proj.SU', 'model.layers.12.self_attn.o_proj.SU', 'model.layers.0.mlp.up_proj.trellis', 'model.layers.11.mlp.gate_proj.tlut', 'model.layers.24.self_attn.q_proj.tlut', 'model.layers.12.self_attn.o_proj.SV', 'model.layers.6.self_attn.v_proj.SU', 'model.layers.28.self_attn.k_proj.SV', 'model.layers.21.mlp.gate_proj.SV', 'model.layers.7.mlp.down_proj.tlut', 'model.layers.23.mlp.down_proj.trellis', 'model.layers.10.mlp.gate_proj.tlut', 'model.layers.9.mlp.down_proj.SU', 'model.layers.24.mlp.down_proj.SU', 'model.layers.27.mlp.up_proj.tlut', 'model.layers.28.mlp.gate_proj.tlut', 'model.layers.10.self_attn.v_proj.SV', 'model.layers.18.mlp.up_proj.SU', 'model.layers.13.mlp.down_proj.trellis', 'model.layers.3.self_attn.v_proj.tlut', 'model.layers.10.self_attn.q_proj.SV', 'model.layers.2.self_attn.q_proj.tlut', 'model.layers.16.self_attn.v_proj.SV', 'model.layers.20.self_attn.v_proj.trellis', 'model.layers.24.mlp.down_proj.tlut', 'model.layers.25.mlp.up_proj.tlut', 'model.layers.11.mlp.up_proj.SV', 'model.layers.30.self_attn.k_proj.tlut', 'model.layers.17.self_attn.k_proj.trellis', 'model.layers.11.self_attn.k_proj.tlut', 'model.layers.16.self_attn.k_proj.SV', 'model.layers.26.self_attn.k_proj.SU', 'model.layers.28.mlp.down_proj.tlut', 'model.layers.6.mlp.down_proj.trellis', 'model.layers.9.self_attn.o_proj.tlut', 'model.layers.30.mlp.down_proj.SU', 'model.layers.6.self_attn.o_proj.SU', 'model.layers.3.self_attn.k_proj.SV', 'model.layers.12.self_attn.v_proj.SV', 'model.layers.6.mlp.down_proj.SU', 'model.layers.27.mlp.down_proj.trellis', 'model.layers.20.mlp.up_proj.tlut', 'model.layers.5.self_attn.k_proj.SU', 'model.layers.14.self_attn.v_proj.SU', 'model.layers.26.mlp.up_proj.trellis', 'model.layers.27.self_attn.k_proj.SV', 'model.layers.2.mlp.up_proj.tlut', 'model.layers.10.self_attn.v_proj.trellis', 'model.layers.10.self_attn.q_proj.SU', 'model.layers.20.self_attn.q_proj.SU', 'model.layers.6.mlp.up_proj.SV', 'model.layers.7.mlp.up_proj.SU', 'model.layers.1.self_attn.v_proj.SV', 'model.layers.29.mlp.down_proj.tlut', 'model.layers.1.mlp.down_proj.SU', 'model.layers.25.self_attn.o_proj.tlut', 'model.layers.5.self_attn.q_proj.SU', 'model.layers.14.mlp.gate_proj.trellis', 'model.layers.31.self_attn.o_proj.SV', 'model.layers.25.mlp.down_proj.trellis', 'model.layers.20.mlp.down_proj.SV', 'model.layers.29.self_attn.k_proj.SU', 'model.layers.31.mlp.down_proj.SU', 'model.layers.18.mlp.up_proj.tlut', 'model.layers.1.mlp.gate_proj.tlut', 'model.layers.19.self_attn.q_proj.tlut', 'model.layers.7.self_attn.v_proj.tlut', 'model.layers.1.mlp.down_proj.trellis', 'model.layers.5.self_attn.v_proj.trellis', 'model.layers.11.mlp.down_proj.tlut', 'model.layers.14.self_attn.o_proj.SU', 'model.layers.15.mlp.up_proj.trellis', 'model.layers.4.mlp.down_proj.tlut', 'model.layers.21.mlp.down_proj.SU', 'model.layers.27.self_attn.q_proj.SV', 'model.layers.28.self_attn.o_proj.trellis', 'model.layers.4.mlp.up_proj.tlut', 'model.layers.7.self_attn.k_proj.SV', 'model.layers.1.self_attn.o_proj.tlut', 'model.layers.14.mlp.up_proj.SU', 'model.layers.15.self_attn.q_proj.tlut', 'model.layers.7.self_attn.q_proj.tlut', 'model.layers.29.self_attn.q_proj.tlut', 'model.layers.15.mlp.up_proj.SU', 'model.layers.7.mlp.up_proj.tlut', 'model.layers.9.mlp.down_proj.tlut', 'model.layers.26.self_attn.v_proj.tlut', 'model.layers.15.mlp.gate_proj.tlut', 'model.layers.9.mlp.up_proj.trellis', 'model.layers.14.mlp.up_proj.tlut', 'model.layers.21.mlp.up_proj.trellis', 'model.layers.25.self_attn.k_proj.SV', 'model.layers.8.mlp.up_proj.trellis', 'model.layers.9.self_attn.v_proj.tlut', 'model.layers.6.self_attn.v_proj.SV', 'model.layers.15.mlp.gate_proj.trellis', 'model.layers.15.self_attn.q_proj.SU', 'model.layers.6.self_attn.q_proj.trellis', 'model.layers.18.self_attn.o_proj.SV', 'model.layers.11.mlp.down_proj.SU', 'model.layers.26.self_attn.o_proj.SV', 'model.layers.7.self_attn.q_proj.SU', 'model.layers.7.self_attn.v_proj.trellis', 'model.layers.18.mlp.gate_proj.SV', 'model.layers.23.mlp.gate_proj.tlut', 'model.layers.26.mlp.gate_proj.SU', 'model.layers.1.self_attn.v_proj.tlut', 'model.layers.16.mlp.gate_proj.trellis', 'model.layers.22.self_attn.q_proj.tlut', 'model.layers.31.mlp.down_proj.tlut', 'model.layers.18.mlp.gate_proj.SU', 'model.layers.6.self_attn.q_proj.SV', 'model.layers.30.mlp.gate_proj.tlut', 'model.layers.16.self_attn.o_proj.trellis', 'model.layers.28.self_attn.k_proj.SU', 'model.layers.31.mlp.up_proj.trellis', 'model.layers.2.self_attn.o_proj.tlut', 'model.layers.23.mlp.up_proj.SV', 'model.layers.10.self_attn.o_proj.tlut', 'model.layers.19.mlp.down_proj.SU', 'model.layers.24.self_attn.o_proj.trellis', 'model.layers.2.mlp.down_proj.tlut', 'model.layers.28.self_attn.v_proj.tlut', 'model.layers.21.self_attn.o_proj.SU', 'model.layers.0.mlp.gate_proj.tlut', 'model.layers.1.mlp.gate_proj.trellis', 'model.layers.17.mlp.gate_proj.SU', 'model.layers.12.self_attn.k_proj.SV', 'model.layers.22.mlp.down_proj.SU', 'model.layers.14.self_attn.q_proj.tlut', 'model.layers.29.mlp.gate_proj.SU', 'model.layers.29.mlp.gate_proj.trellis', 'model.layers.27.self_attn.o_proj.trellis', 'model.layers.29.self_attn.v_proj.tlut', 'model.layers.22.self_attn.o_proj.trellis', 'model.layers.27.self_attn.o_proj.SU', 'model.layers.28.mlp.up_proj.trellis', 'model.layers.10.mlp.down_proj.SU', 'model.layers.11.self_attn.v_proj.SU', 'model.layers.30.self_attn.q_proj.SV', 'model.layers.9.self_attn.k_proj.SU', 'model.layers.9.self_attn.q_proj.SU', 'model.layers.0.self_attn.v_proj.trellis', 'model.layers.1.mlp.down_proj.tlut', 'model.layers.3.self_attn.q_proj.SU', 'model.layers.9.self_attn.k_proj.trellis', 'model.layers.0.self_attn.o_proj.trellis', 'model.layers.6.self_attn.k_proj.trellis', 'model.layers.14.self_attn.v_proj.SV', 'model.layers.17.mlp.up_proj.trellis', 'model.layers.21.self_attn.q_proj.trellis', 'model.layers.23.mlp.down_proj.tlut', 'model.layers.24.self_attn.v_proj.trellis', 'model.layers.26.mlp.gate_proj.tlut', 'model.layers.31.self_attn.k_proj.trellis', 'model.layers.27.self_attn.k_proj.trellis', 'model.layers.0.self_attn.k_proj.tlut', 'model.layers.13.mlp.up_proj.SU', 'model.layers.24.mlp.gate_proj.SV', 'model.layers.8.self_attn.v_proj.tlut', 'model.layers.28.self_attn.q_proj.SV', 'model.layers.0.mlp.down_proj.tlut', 'model.layers.17.self_attn.o_proj.trellis', 'model.layers.31.self_attn.k_proj.tlut', 'model.layers.1.mlp.gate_proj.SU', 'model.layers.23.self_attn.v_proj.SV', 'model.layers.1.mlp.up_proj.SU', 'model.layers.22.mlp.up_proj.SV', 'model.layers.28.mlp.up_proj.tlut', 'model.layers.7.mlp.down_proj.SU', 'model.layers.30.self_attn.v_proj.trellis', 'model.layers.16.self_attn.k_proj.trellis', 'model.layers.13.self_attn.o_proj.trellis', 'model.layers.26.mlp.gate_proj.trellis', 'model.layers.13.self_attn.k_proj.SV', 'model.layers.13.self_attn.q_proj.SU', 'model.layers.27.self_attn.k_proj.tlut', 'model.layers.1.self_attn.k_proj.trellis', 'model.layers.19.self_attn.o_proj.trellis', 'model.layers.19.self_attn.v_proj.trellis', 'model.layers.2.mlp.up_proj.SV', 'model.layers.3.self_attn.o_proj.trellis', 'model.layers.31.mlp.up_proj.SV', 'model.layers.20.self_attn.q_proj.SV', 'model.layers.11.mlp.down_proj.SV', 'model.layers.21.mlp.down_proj.tlut', 'model.layers.19.mlp.up_proj.SU', 'model.layers.5.self_attn.k_proj.trellis', 'model.layers.24.mlp.gate_proj.SU', 'model.layers.9.mlp.gate_proj.SU', 'model.layers.22.mlp.gate_proj.trellis', 'model.layers.17.mlp.down_proj.SU', 'model.layers.28.self_attn.k_proj.tlut', 'model.layers.15.mlp.up_proj.SV', 'model.layers.30.mlp.down_proj.tlut', 'model.layers.9.self_attn.o_proj.SU', 'model.layers.17.mlp.up_proj.SU', 'model.layers.2.self_attn.q_proj.SV', 'model.layers.4.self_attn.o_proj.trellis', 'model.layers.26.self_attn.q_proj.tlut', 'model.layers.12.mlp.down_proj.SU', 'model.layers.0.self_attn.q_proj.trellis', 'model.layers.12.self_attn.k_proj.trellis', 'model.layers.22.mlp.gate_proj.SU', 'model.layers.23.self_attn.o_proj.tlut', 'model.layers.24.mlp.gate_proj.tlut', 'model.layers.25.mlp.down_proj.tlut', 'model.layers.31.self_attn.q_proj.SU', 'model.layers.3.mlp.up_proj.trellis', 'model.layers.7.mlp.gate_proj.trellis', 'model.layers.15.mlp.down_proj.trellis', 'model.layers.16.mlp.down_proj.SU', 'model.layers.11.mlp.down_proj.trellis', 'model.layers.28.mlp.down_proj.trellis', 'model.layers.13.self_attn.v_proj.SU', 'model.layers.26.mlp.up_proj.SU', 'model.layers.27.self_attn.v_proj.SU', 'model.layers.4.mlp.gate_proj.SV', 'model.layers.6.self_attn.v_proj.tlut', 'model.layers.10.mlp.down_proj.tlut', 'model.layers.17.self_attn.k_proj.SU', 'model.layers.23.self_attn.o_proj.SU', 'model.layers.30.mlp.gate_proj.SV', 'model.layers.2.mlp.up_proj.SU', 'model.layers.16.mlp.down_proj.tlut', 'model.layers.7.self_attn.v_proj.SV', 'model.layers.27.self_attn.v_proj.tlut', 'model.layers.23.self_attn.v_proj.SU', 'model.layers.5.mlp.gate_proj.SU', 'model.layers.19.mlp.down_proj.SV', 'model.layers.31.mlp.gate_proj.trellis', 'model.layers.20.mlp.down_proj.SU', 'model.layers.8.self_attn.k_proj.SV', 'model.layers.24.self_attn.o_proj.tlut', 'model.layers.24.mlp.up_proj.trellis', 'model.layers.31.mlp.gate_proj.SV', 'model.layers.19.self_attn.v_proj.SV', 'model.layers.25.self_attn.k_proj.tlut', 'model.layers.31.mlp.up_proj.SU', 'model.layers.9.mlp.up_proj.SV', 'model.layers.26.self_attn.k_proj.tlut', 'model.layers.19.self_attn.v_proj.tlut', 'model.layers.22.self_attn.o_proj.SU', 'model.layers.30.mlp.up_proj.SU', 'model.layers.1.mlp.up_proj.tlut', 'model.layers.5.mlp.gate_proj.trellis', 'model.layers.4.self_attn.o_proj.SV', 'model.layers.24.mlp.down_proj.SV', 'model.layers.12.self_attn.k_proj.SU', 'model.layers.16.self_attn.v_proj.SU', 'model.layers.18.self_attn.k_proj.trellis', 'model.layers.2.self_attn.o_proj.trellis', 'model.layers.21.self_attn.o_proj.SV', 'model.layers.8.mlp.up_proj.SV', 'model.layers.3.mlp.up_proj.SV', 'model.layers.22.self_attn.v_proj.trellis', 'model.layers.24.self_attn.q_proj.SV', 'model.layers.29.self_attn.o_proj.SV', 'model.layers.22.mlp.up_proj.tlut', 'model.layers.28.mlp.down_proj.SV', 'model.layers.12.mlp.up_proj.SU', 'model.layers.10.mlp.up_proj.tlut', 'model.layers.19.self_attn.k_proj.tlut', 'model.layers.25.mlp.gate_proj.trellis', 'model.layers.24.self_attn.v_proj.tlut', 'model.layers.5.self_attn.q_proj.tlut', 'model.layers.17.mlp.gate_proj.tlut', 'model.layers.7.self_attn.o_proj.SU', 'model.layers.24.self_attn.q_proj.trellis', 'model.layers.10.mlp.up_proj.SU', 'model.layers.14.mlp.down_proj.SV', 'model.layers.22.self_attn.v_proj.SU', 'model.layers.18.self_attn.q_proj.trellis', 'model.layers.31.self_attn.k_proj.SU', 'model.layers.19.self_attn.k_proj.trellis', 'model.layers.7.mlp.up_proj.SV', 'model.layers.18.self_attn.v_proj.tlut', 'model.layers.13.mlp.gate_proj.SV', 'model.layers.16.self_attn.k_proj.SU', 'model.layers.4.mlp.down_proj.SU', 'model.layers.18.mlp.up_proj.trellis', 'model.layers.20.mlp.gate_proj.tlut', 'model.layers.11.self_attn.o_proj.tlut', 'model.layers.0.mlp.down_proj.trellis', 'model.layers.13.mlp.down_proj.SV', 'model.layers.10.self_attn.q_proj.tlut', 'model.layers.6.mlp.down_proj.SV', 'model.layers.12.mlp.up_proj.SV', 'model.layers.25.mlp.gate_proj.tlut', 'model.layers.4.self_attn.q_proj.SV', 'model.layers.5.mlp.down_proj.SV', 'model.layers.2.mlp.gate_proj.SU', 'model.layers.14.self_attn.o_proj.tlut', 'model.layers.14.self_attn.k_proj.trellis', 'model.layers.4.self_attn.q_proj.trellis', 'model.layers.8.mlp.gate_proj.SV', 'model.layers.26.self_attn.q_proj.trellis', 'model.layers.9.self_attn.v_proj.SV', 'model.layers.30.self_attn.o_proj.trellis', 'model.layers.20.self_attn.o_proj.trellis', 'model.layers.7.self_attn.o_proj.trellis', 'model.layers.27.mlp.down_proj.tlut', 'model.layers.28.self_attn.k_proj.trellis', 'model.layers.31.self_attn.q_proj.trellis', 'model.layers.0.self_attn.q_proj.tlut', 'model.layers.9.mlp.up_proj.SU', 'model.layers.26.mlp.down_proj.trellis', 'model.layers.18.self_attn.v_proj.SV', 'model.layers.3.mlp.gate_proj.trellis', 'model.layers.20.self_attn.v_proj.SU', 'model.layers.24.self_attn.q_proj.SU', 'model.layers.10.self_attn.v_proj.tlut', 'model.layers.17.self_attn.q_proj.SV', 'model.layers.20.self_attn.o_proj.SU', 'model.layers.13.self_attn.o_proj.SV', 'model.layers.12.mlp.up_proj.tlut', 'model.layers.11.mlp.up_proj.tlut', 'model.layers.26.self_attn.v_proj.trellis', 'model.layers.31.self_attn.k_proj.SV', 'model.layers.9.self_attn.q_proj.trellis', 'model.layers.17.self_attn.q_proj.tlut', 'model.layers.21.self_attn.k_proj.tlut', 'model.layers.28.self_attn.v_proj.trellis', 'model.layers.21.self_attn.o_proj.tlut', 'model.layers.0.mlp.gate_proj.SV', 'model.layers.8.self_attn.o_proj.tlut', 'model.layers.23.self_attn.k_proj.trellis', 'model.layers.29.self_attn.q_proj.SU', 'model.layers.19.mlp.gate_proj.SU', 'model.layers.30.self_attn.k_proj.trellis', 'model.layers.24.mlp.gate_proj.trellis', 'model.layers.4.mlp.up_proj.SV', 'model.layers.19.self_attn.o_proj.tlut', 'model.layers.13.self_attn.q_proj.trellis', 'model.layers.21.mlp.up_proj.SU', 'model.layers.27.mlp.gate_proj.trellis', 'model.layers.7.mlp.down_proj.trellis', 'model.layers.15.self_attn.v_proj.tlut', 'model.layers.23.self_attn.o_proj.SV', 'model.layers.17.self_attn.k_proj.SV', 'model.layers.4.self_attn.k_proj.trellis', 'model.layers.14.self_attn.q_proj.trellis', 'model.layers.22.mlp.down_proj.SV', 'model.layers.1.self_attn.q_proj.SU', 'model.layers.10.self_attn.k_proj.tlut', 'model.layers.17.mlp.gate_proj.SV', 'model.layers.22.self_attn.k_proj.SU', 'model.layers.3.mlp.up_proj.SU', 'model.layers.20.mlp.gate_proj.SV', 'model.layers.21.self_attn.q_proj.tlut', 'model.layers.21.self_attn.v_proj.tlut', 'model.layers.11.mlp.up_proj.SU', 'model.layers.26.self_attn.q_proj.SU', 'model.layers.30.mlp.up_proj.SV', 'model.layers.6.self_attn.o_proj.trellis', 'model.layers.10.self_attn.o_proj.trellis', 'model.layers.17.self_attn.q_proj.trellis', 'model.layers.16.mlp.down_proj.trellis', 'model.layers.21.mlp.gate_proj.SU', 'model.layers.17.self_attn.v_proj.tlut', 'model.layers.22.self_attn.k_proj.tlut', 'model.layers.28.self_attn.o_proj.tlut', 'model.layers.8.mlp.down_proj.tlut', 'model.layers.21.mlp.gate_proj.trellis', 'model.layers.29.mlp.down_proj.trellis', 'model.layers.8.mlp.gate_proj.trellis', 'model.layers.11.mlp.gate_proj.SU', 'model.layers.24.mlp.down_proj.trellis', 'model.layers.31.mlp.gate_proj.SU', 'model.layers.19.mlp.up_proj.trellis', 'model.layers.3.self_attn.o_proj.SU', 'model.layers.20.self_attn.v_proj.tlut', 'model.layers.0.mlp.gate_proj.SU', 'model.layers.15.mlp.gate_proj.SV', 'model.layers.4.mlp.down_proj.trellis', 'model.layers.9.self_attn.q_proj.SV', 'model.layers.5.self_attn.k_proj.SV', 'model.layers.12.mlp.gate_proj.SV', 'model.layers.17.mlp.up_proj.tlut', 'model.layers.1.self_attn.v_proj.trellis', 'model.layers.8.mlp.up_proj.tlut', 'model.layers.3.mlp.down_proj.trellis', 'model.layers.13.self_attn.o_proj.SU', 'model.layers.25.mlp.gate_proj.SU', 'model.layers.14.self_attn.q_proj.SU', 'model.layers.0.self_attn.q_proj.SU', 'model.layers.16.self_attn.k_proj.tlut', 'model.layers.9.mlp.gate_proj.tlut', 'model.layers.2.mlp.gate_proj.trellis', 'model.layers.14.mlp.down_proj.trellis', 'model.layers.15.self_attn.q_proj.trellis', 'model.layers.21.self_attn.k_proj.trellis', 'model.layers.16.mlp.down_proj.SV', 'model.layers.8.self_attn.o_proj.trellis', 'model.layers.31.self_attn.o_proj.SU', 'model.layers.0.mlp.up_proj.tlut', 'model.layers.14.mlp.down_proj.tlut', 'model.layers.20.mlp.up_proj.SV', 'model.layers.24.self_attn.v_proj.SV', 'model.layers.14.mlp.up_proj.trellis', 'model.layers.15.self_attn.q_proj.SV', 'model.layers.7.self_attn.o_proj.tlut', 'model.layers.8.self_attn.o_proj.SU', 'model.layers.30.self_attn.q_proj.tlut', 'model.layers.12.mlp.down_proj.SV', 'model.layers.21.mlp.up_proj.tlut', 'model.layers.0.mlp.gate_proj.trellis', 'model.layers.22.self_attn.o_proj.SV', 'model.layers.13.mlp.up_proj.SV', 'model.layers.25.self_attn.q_proj.SU', 'model.layers.4.mlp.gate_proj.tlut', 'model.layers.4.self_attn.q_proj.tlut', 'model.layers.10.mlp.gate_proj.trellis', 'model.layers.11.self_attn.q_proj.SV', 'model.layers.17.self_attn.q_proj.SU', 'model.layers.29.self_attn.q_proj.SV', 'model.layers.31.mlp.down_proj.SV', 'model.layers.7.self_attn.q_proj.SV', 'model.layers.3.mlp.gate_proj.tlut', 'model.layers.8.self_attn.v_proj.SV', 'model.layers.11.self_attn.o_proj.trellis', 'model.layers.5.mlp.up_proj.trellis', 'model.layers.6.self_attn.o_proj.SV', 'model.layers.23.mlp.down_proj.SU', 'model.layers.10.self_attn.v_proj.SU', 'model.layers.23.self_attn.v_proj.tlut', 'model.layers.6.self_attn.q_proj.tlut', 'model.layers.18.self_attn.q_proj.tlut', 'model.layers.16.self_attn.v_proj.trellis', 'model.layers.1.mlp.down_proj.SV', 'model.layers.28.mlp.down_proj.SU', 'model.layers.18.self_attn.o_proj.tlut', 'model.layers.20.mlp.gate_proj.trellis', 'model.layers.12.mlp.gate_proj.tlut', 'model.layers.6.self_attn.k_proj.SV', 'model.layers.14.self_attn.k_proj.SV', 'model.layers.20.self_attn.o_proj.SV', 'model.layers.2.self_attn.k_proj.SU', 'model.layers.14.self_attn.o_proj.trellis', 'model.layers.19.self_attn.o_proj.SV', 'model.layers.19.mlp.gate_proj.trellis', 'model.layers.29.self_attn.v_proj.SU', 'model.layers.8.self_attn.v_proj.SU', 'model.layers.18.self_attn.o_proj.trellis', 'model.layers.15.mlp.up_proj.tlut', 'model.layers.26.self_attn.o_proj.tlut', 'model.layers.2.mlp.gate_proj.SV', 'model.layers.2.self_attn.k_proj.trellis', 'model.layers.21.self_attn.v_proj.SV', 'model.layers.3.mlp.down_proj.tlut', 'model.layers.31.mlp.gate_proj.tlut', 'model.layers.1.mlp.up_proj.trellis', 'model.layers.13.mlp.down_proj.tlut', 'model.layers.29.self_attn.v_proj.trellis', 'model.layers.17.self_attn.o_proj.tlut', 'model.layers.28.self_attn.o_proj.SV', 'model.layers.29.self_attn.o_proj.tlut', 'model.layers.21.mlp.gate_proj.tlut', 'model.layers.24.self_attn.k_proj.trellis', 'model.layers.21.self_attn.k_proj.SU', 'model.layers.10.mlp.gate_proj.SU', 'model.layers.13.self_attn.v_proj.trellis', 'model.layers.25.self_attn.v_proj.tlut', 'model.layers.10.self_attn.k_proj.SU', 'model.layers.12.self_attn.q_proj.trellis', 'model.layers.23.self_attn.k_proj.tlut', 'model.layers.21.mlp.up_proj.SV', 'model.layers.23.mlp.gate_proj.SV', 'model.layers.29.mlp.up_proj.SU', 'model.layers.25.self_attn.k_proj.trellis', 'model.layers.5.mlp.up_proj.SV', 'model.layers.10.self_attn.o_proj.SU', 'model.layers.11.self_attn.v_proj.trellis', 'model.layers.27.mlp.down_proj.SU', 'model.layers.8.self_attn.k_proj.trellis', 'model.layers.9.self_attn.o_proj.trellis', 'model.layers.27.self_attn.v_proj.SV', 'model.layers.6.mlp.up_proj.tlut', 'model.layers.12.mlp.up_proj.trellis', 'model.layers.30.mlp.gate_proj.SU', 'model.layers.17.mlp.down_proj.SV', 'model.layers.0.self_attn.k_proj.SV', 'model.layers.23.mlp.up_proj.trellis', 'model.layers.29.mlp.up_proj.SV', 'model.layers.12.mlp.gate_proj.trellis', 'model.layers.4.self_attn.q_proj.SU', 'model.layers.5.mlp.up_proj.tlut', 'model.layers.22.self_attn.q_proj.SV', 'model.layers.23.self_attn.k_proj.SV', 'model.layers.18.mlp.down_proj.trellis', 'model.layers.6.self_attn.k_proj.SU', 'model.layers.2.mlp.down_proj.trellis', 'model.layers.19.self_attn.k_proj.SV', 'model.layers.0.self_attn.v_proj.tlut', 'model.layers.2.self_attn.v_proj.SV', 'model.layers.16.self_attn.q_proj.tlut', 'model.layers.21.self_attn.q_proj.SV', 'model.layers.30.self_attn.q_proj.SU', 'model.layers.17.mlp.up_proj.SV', 'model.layers.22.self_attn.k_proj.trellis', 'model.layers.8.mlp.gate_proj.SU', 'model.layers.4.self_attn.k_proj.tlut', 'model.layers.21.self_attn.k_proj.SV', 'model.layers.5.self_attn.o_proj.tlut', 'model.layers.19.self_attn.v_proj.SU', 'model.layers.20.self_attn.k_proj.SU', 'model.layers.20.self_attn.q_proj.tlut', 'model.layers.23.self_attn.q_proj.SV', 'model.layers.12.mlp.down_proj.trellis', 'model.layers.30.self_attn.k_proj.SU', 'model.layers.25.self_attn.v_proj.SV', 'model.layers.14.mlp.gate_proj.tlut', 'model.layers.26.self_attn.k_proj.SV', 'model.layers.2.mlp.up_proj.trellis', 'model.layers.31.self_attn.v_proj.SV', 'model.layers.4.self_attn.k_proj.SU', 'model.layers.7.self_attn.k_proj.tlut', 'model.layers.5.mlp.gate_proj.tlut', 'model.layers.15.self_attn.o_proj.SV', 'model.layers.4.mlp.gate_proj.SU', 'model.layers.23.self_attn.o_proj.trellis', 'model.layers.30.self_attn.v_proj.tlut', 'model.layers.1.self_attn.k_proj.SV', 'model.layers.25.self_attn.q_proj.trellis', 'model.layers.29.self_attn.k_proj.trellis', 'model.layers.20.self_attn.q_proj.trellis', 'model.layers.29.self_attn.v_proj.SV', 'model.layers.18.self_attn.q_proj.SU', 'model.layers.23.mlp.down_proj.SV', 'model.layers.13.self_attn.q_proj.SV', 'model.layers.18.self_attn.o_proj.SU', 'model.layers.13.self_attn.k_proj.trellis', 'model.layers.17.mlp.down_proj.tlut', 'model.layers.21.self_attn.q_proj.SU', 'model.layers.30.mlp.gate_proj.trellis', 'model.layers.5.self_attn.v_proj.SV', 'model.layers.9.mlp.down_proj.SV', 'model.layers.29.self_attn.k_proj.SV', 'model.layers.8.self_attn.v_proj.trellis', 'model.layers.3.self_attn.o_proj.tlut', 'model.layers.14.self_attn.v_proj.tlut', 'model.layers.27.mlp.up_proj.SV', 'model.layers.16.mlp.gate_proj.SU', 'model.layers.16.self_attn.q_proj.SV', 'model.layers.10.self_attn.q_proj.trellis', 'model.layers.9.self_attn.o_proj.SV', 'model.layers.5.self_attn.v_proj.tlut', 'model.layers.3.self_attn.q_proj.trellis', 'model.layers.8.self_attn.k_proj.tlut', 'model.layers.25.self_attn.v_proj.trellis', 'model.layers.6.mlp.up_proj.SU', 'model.layers.31.self_attn.v_proj.trellis', 'model.layers.1.self_attn.o_proj.trellis', 'model.layers.13.self_attn.o_proj.tlut', 'model.layers.22.mlp.up_proj.trellis', 'model.layers.20.mlp.gate_proj.SU', 'model.layers.2.mlp.down_proj.SU', 'model.layers.31.self_attn.q_proj.tlut', 'model.layers.5.mlp.up_proj.SU', 'model.layers.8.self_attn.q_proj.trellis', 'model.layers.5.self_attn.o_proj.SU', 'model.layers.16.mlp.gate_proj.tlut', 'model.layers.20.mlp.up_proj.SU', 'model.layers.28.self_attn.v_proj.SU', 'model.layers.13.mlp.up_proj.tlut', 'model.layers.12.mlp.down_proj.tlut', 'model.layers.19.self_attn.k_proj.SU', 'model.layers.8.mlp.down_proj.trellis', 'model.layers.0.self_attn.q_proj.SV', 'model.layers.23.self_attn.k_proj.SU', 'model.layers.23.self_attn.v_proj.trellis', 'model.layers.31.self_attn.v_proj.tlut', 'model.layers.30.self_attn.o_proj.SV', 'model.layers.14.mlp.gate_proj.SU', 'model.layers.2.self_attn.o_proj.SU', 'model.layers.4.self_attn.v_proj.SU', 'model.layers.8.mlp.down_proj.SV', 'model.layers.12.self_attn.k_proj.tlut', 'model.layers.20.self_attn.k_proj.SV', 'model.layers.20.mlp.up_proj.trellis', 'model.layers.16.mlp.up_proj.tlut', 'model.layers.3.self_attn.k_proj.SU', 'model.layers.27.mlp.up_proj.SU', 'model.layers.26.mlp.down_proj.SU', 'model.layers.2.self_attn.q_proj.SU', 'model.layers.29.mlp.up_proj.trellis', 'model.layers.3.mlp.up_proj.tlut', 'model.layers.10.mlp.down_proj.trellis', 'model.layers.30.self_attn.k_proj.SV', 'model.layers.18.mlp.up_proj.SV', 'model.layers.22.self_attn.k_proj.SV', 'model.layers.22.mlp.up_proj.SU', 'model.layers.22.self_attn.v_proj.SV', 'model.layers.13.mlp.gate_proj.SU', 'model.layers.3.self_attn.v_proj.SU', 'model.layers.4.self_attn.v_proj.trellis', 'model.layers.19.mlp.down_proj.trellis', 'model.layers.11.self_attn.k_proj.SU', 'model.layers.3.self_attn.k_proj.trellis', 'model.layers.17.self_attn.v_proj.SV', 'model.layers.21.self_attn.v_proj.SU', 'model.layers.29.mlp.gate_proj.SV', 'model.layers.24.self_attn.o_proj.SU', 'model.layers.5.self_attn.q_proj.SV', 'model.layers.19.self_attn.q_proj.SU', 'model.layers.18.self_attn.q_proj.SV', 'model.layers.13.self_attn.v_proj.SV', 'model.layers.22.mlp.gate_proj.tlut', 'model.layers.9.self_attn.v_proj.SU', 'model.layers.23.mlp.gate_proj.SU', 'model.layers.18.mlp.down_proj.SU', 'model.layers.26.self_attn.o_proj.trellis', 'model.layers.11.mlp.gate_proj.trellis', 'model.layers.22.self_attn.q_proj.SU', 'model.layers.5.self_attn.o_proj.SV', 'model.layers.12.self_attn.q_proj.SU', 'model.layers.24.mlp.up_proj.SV', 'model.layers.17.self_attn.o_proj.SV', 'model.layers.14.self_attn.v_proj.trellis', 'model.layers.14.self_attn.k_proj.tlut', 'model.layers.18.self_attn.k_proj.SV', 'model.layers.15.mlp.down_proj.SU', 'model.layers.27.mlp.down_proj.SV', 'model.layers.19.mlp.gate_proj.tlut', 'model.layers.14.mlp.up_proj.SV', 'model.layers.3.self_attn.q_proj.tlut', 'model.layers.8.self_attn.k_proj.SU', 'model.layers.19.self_attn.q_proj.trellis', 'model.layers.17.self_attn.k_proj.tlut', 'model.layers.11.mlp.up_proj.trellis', 'model.layers.21.self_attn.o_proj.trellis', 'model.layers.31.self_attn.v_proj.SU', 'model.layers.1.self_attn.k_proj.tlut', 'model.layers.7.mlp.gate_proj.tlut', 'model.layers.16.self_attn.o_proj.SU', 'model.layers.4.mlp.up_proj.SU', 'model.layers.15.self_attn.v_proj.trellis', 'model.layers.5.self_attn.o_proj.trellis', 'model.layers.8.self_attn.q_proj.SV', 'model.layers.17.self_attn.v_proj.SU', 'model.layers.24.mlp.up_proj.tlut', 'model.layers.4.self_attn.o_proj.tlut', 'model.layers.3.mlp.gate_proj.SV', 'model.layers.20.mlp.down_proj.tlut', 'model.layers.0.self_attn.o_proj.SV', 'model.layers.16.self_attn.q_proj.trellis', 'model.layers.7.mlp.gate_proj.SV', 'model.layers.17.self_attn.v_proj.trellis', 'model.layers.5.self_attn.v_proj.SU', 'model.layers.26.self_attn.k_proj.trellis', 'model.layers.31.self_attn.o_proj.trellis', 'model.layers.12.self_attn.v_proj.SU', 'model.layers.19.self_attn.q_proj.SV', 'model.layers.15.self_attn.k_proj.tlut', 'model.layers.25.mlp.gate_proj.SV', 'model.layers.30.mlp.up_proj.trellis', 'model.layers.30.self_attn.v_proj.SU', 'model.layers.11.self_attn.v_proj.SV', 'model.layers.25.mlp.up_proj.SU', 'model.layers.31.mlp.up_proj.tlut', 'model.layers.8.self_attn.q_proj.SU', 'model.layers.5.mlp.down_proj.tlut', 'model.layers.25.mlp.up_proj.SV', 'model.layers.5.mlp.down_proj.SU', 'model.layers.12.self_attn.v_proj.trellis', 'model.layers.30.self_attn.q_proj.trellis', 'model.layers.28.self_attn.q_proj.tlut', 'model.layers.18.self_attn.v_proj.trellis', 'model.layers.7.self_attn.o_proj.SV', 'model.layers.19.mlp.down_proj.tlut', 'model.layers.16.self_attn.o_proj.tlut', 'model.layers.18.mlp.down_proj.SV', 'model.layers.28.self_attn.q_proj.trellis', 'model.layers.15.mlp.down_proj.tlut', 'model.layers.4.self_attn.v_proj.tlut', 'model.layers.25.self_attn.q_proj.SV', 'model.layers.28.mlp.up_proj.SU', 'model.layers.0.mlp.up_proj.SU', 'model.layers.12.self_attn.o_proj.trellis', 'model.layers.3.self_attn.q_proj.SV', 'model.layers.23.mlp.up_proj.tlut', 'model.layers.0.mlp.down_proj.SU', 'model.layers.3.mlp.down_proj.SU', 'model.layers.5.mlp.down_proj.trellis', 'model.layers.29.mlp.down_proj.SU', 'model.layers.13.self_attn.v_proj.tlut', 'model.layers.4.mlp.down_proj.SV', 'model.layers.5.self_attn.q_proj.trellis', 'model.layers.14.mlp.down_proj.SU', 'model.layers.22.mlp.down_proj.tlut', 'model.layers.10.mlp.up_proj.trellis', 'model.layers.12.mlp.gate_proj.SU', 'model.layers.23.mlp.gate_proj.trellis', 'model.layers.0.self_attn.v_proj.SU', 'model.layers.16.mlp.up_proj.SU', 'model.layers.15.self_attn.k_proj.trellis', 'model.layers.26.self_attn.o_proj.SU', 'model.layers.26.self_attn.q_proj.SV', 'model.layers.30.mlp.down_proj.SV', 'model.layers.31.self_attn.o_proj.tlut', 'model.layers.28.mlp.gate_proj.SU', 'model.layers.5.mlp.gate_proj.SV', 'model.layers.6.mlp.gate_proj.SV', 'model.layers.6.self_attn.o_proj.tlut', 'model.layers.11.self_attn.k_proj.trellis', 'model.layers.16.self_attn.o_proj.SV', 'model.layers.8.mlp.down_proj.SU', 'model.layers.0.mlp.up_proj.SV', 'model.layers.8.self_attn.q_proj.tlut', 'model.layers.15.self_attn.v_proj.SU', 'model.layers.16.mlp.up_proj.trellis', 'model.layers.9.mlp.up_proj.tlut', 'model.layers.26.mlp.up_proj.SV', 'model.layers.9.self_attn.v_proj.trellis', 'model.layers.9.mlp.gate_proj.SV', 'model.layers.17.mlp.gate_proj.trellis', 'model.layers.18.self_attn.v_proj.SU', 'model.layers.27.mlp.gate_proj.tlut', 'model.layers.29.self_attn.o_proj.SU', 'model.layers.6.mlp.gate_proj.trellis', 'model.layers.24.mlp.up_proj.SU', 'model.layers.7.self_attn.k_proj.SU', 'model.layers.8.mlp.gate_proj.tlut', 'model.layers.28.self_attn.o_proj.SU', 'model.layers.3.mlp.gate_proj.SU', 'model.layers.9.self_attn.k_proj.SV', 'model.layers.27.self_attn.o_proj.tlut', 'model.layers.10.self_attn.k_proj.SV', 'model.layers.13.self_attn.q_proj.tlut', 'model.layers.1.mlp.up_proj.SV', 'model.layers.19.self_attn.o_proj.SU', 'model.layers.19.mlp.gate_proj.SV', 'model.layers.0.self_attn.k_proj.trellis', 'model.layers.15.self_attn.o_proj.SU', 'model.layers.15.self_attn.o_proj.tlut', 'model.layers.31.self_attn.q_proj.SV', 'model.layers.18.self_attn.k_proj.SU', 'model.layers.21.mlp.down_proj.trellis', 'model.layers.18.mlp.gate_proj.tlut', 'model.layers.28.self_attn.q_proj.SU', 'model.layers.30.self_attn.o_proj.SU', 'model.layers.6.mlp.down_proj.tlut', 'model.layers.1.self_attn.q_proj.tlut', 'model.layers.6.self_attn.v_proj.trellis', 'model.layers.27.self_attn.v_proj.trellis', 'model.layers.27.self_attn.q_proj.tlut', 'model.layers.2.self_attn.k_proj.tlut', 'model.layers.7.mlp.gate_proj.SU', 'model.layers.2.mlp.down_proj.SV', 'model.layers.2.self_attn.q_proj.trellis', 'model.layers.14.self_attn.o_proj.SV', 'model.layers.14.mlp.gate_proj.SV', 'model.layers.8.mlp.up_proj.SU', 'model.layers.29.self_attn.k_proj.tlut', 'model.layers.15.mlp.down_proj.SV', 'model.layers.12.self_attn.q_proj.tlut'}\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at relaxml/Llama-3.1-8B-Instruct-QTIP-2Bit and are newly initialized: ['model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "السؤال: Write a Python function to calculate the area of ​​a rectangle.\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "إجابة النموذج:\n",
            "--------------------------------------------------\n",
            "483roveever Ortareffisoft Orta/stdctoieverreffembertoiagne accord nonequivskytquivtoieverstay\n",
            "--------------------------------------------------\n",
            "\n",
            "==================================================\n",
            "السؤال: Explain to me in detail how the binary search algorithm works.\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f6e8d82ae476>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# اختبار النموذج مع جميع الأسئلة\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_questions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mtest_model_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# اختبار باستخدام سؤال باللغة الإنجليزية أيضًا\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-f6e8d82ae476>\u001b[0m in \u001b[0;36mtest_model_response\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# توليد الإجابة\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     outputs = pipeline(\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# زيادة عدد الكلمات المولدة للحصول على إجابات أكثر اكتمالاً\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                     \u001b[0mchats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mChat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 🐈 🐈 🐈\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m             )\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation_config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2256\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3255\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3257\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    593\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ife5Tx7p_jPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_id = \"relaxml/Llama-3.2-3B-Instruct-Hessians\"\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "Y_vKQNJ7_oL-",
        "outputId": "2ae1f207-e7e6-4a1c-82df-5c54069f41a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized model in relaxml/Llama-3.2-3B-Instruct-Hessians. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-19969c54eb1f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"relaxml/Llama-3.2-3B-Instruct-Hessians\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m pipeline = transformers.pipeline(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    847\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"base_model_name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         config = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    850\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_revision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode_revision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0;34mf\"Unrecognized model in {pretrained_model_name_or_path}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0;34mf\"Should have a `model_type` key in its {CONFIG_NAME}, or contain one of the following strings \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized model in relaxml/Llama-3.2-3B-Instruct-Hessians. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, li..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BvV48C69_qNV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}